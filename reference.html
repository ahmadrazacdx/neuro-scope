<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="API Reference" />
<meta property="og:type" content="website" />
<meta property="og:url" content="reference.html" />
<meta property="og:site_name" content="NeuroScope" />
<meta property="og:description" content="Complete reference for all NeuroScope modules, classes, and functions. Core Module: neuroscope: NeuroScope: A comprehensive neural network framework for learning and prototyping. NeuroScope provide..." />
<meta property="og:image:width" content="1146" />
<meta property="og:image:height" content="600" />
<meta property="og:image" content="_images/social_previews/summary_reference_f2b08a4b.png" />
<meta property="og:image:alt" content="Complete reference for all NeuroScope modules, classes, and functions. Core Module: neuroscope: NeuroScope: A comprehensive neural network framework for learning and prototyping. NeuroScope provide..." />
<meta name="description" content="Complete reference for all NeuroScope modules, classes, and functions. Core Module: neuroscope: NeuroScope: A comprehensive neural network framework for learning and prototyping. NeuroScope provide..." />
<meta name="twitter:card" content="summary_large_image" />
<link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="Visualization Gallery" href="visualization_gallery.html" /><link rel="prev" title="Technical Deep Dive: Neural Network Diagnostics" href="technical_deep_dive.html" />

    <link rel="shortcut icon" href="_static/favicon.svg"/><!-- Generated with Sphinx 8.2.3 and Furo 2025.07.19 -->
        <title>API Reference - NeuroScope 0.1.0</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=25af2a20" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css?v=d90867fb" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  --color-foreground: #1a1a1a;
  --color-background: #ffffff;
  --color-background-secondary: #f8fafc;
  --color-background-hover: #f1f5f9;
  --color-background-border: #e2e8f0;
  --color-sidebar-background: #ffffff;
  --color-sidebar-background-border: #e2e8f0;
  --color-brand-primary: #0f172a;
  --color-brand-content: #334155;
  --color-accent: #3b82f6;
  --color-accent-2: #1e40af;
  --color-link: #2563eb;
  --color-link--hover: #1d4ed8;
  --color-inline-code-background: #f1f5f9;
  --color-highlighted-background: #fef3c7;
  --color-highlighted-text: #92400e;
  --color-admonition-background: #f8fafc;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  --color-foreground: #e2e8f0;
  --color-background: #0f172a;
  --color-background-secondary: #1e293b;
  --color-background-hover: #334155;
  --color-background-border: #475569;
  --color-sidebar-background: #1e293b;
  --color-sidebar-background-border: #334155;
  --color-brand-primary: #f1f5f9;
  --color-brand-content: #cbd5e1;
  --color-accent: #60a5fa;
  --color-accent-2: #3b82f6;
  --color-link: #60a5fa;
  --color-link--hover: #93c5fd;
  --color-inline-code-background: #334155;
  --color-highlighted-background: #374151;
  --color-highlighted-text: #fbbf24;
  --color-admonition-background: #1e293b;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  --color-foreground: #e2e8f0;
  --color-background: #0f172a;
  --color-background-secondary: #1e293b;
  --color-background-hover: #334155;
  --color-background-border: #475569;
  --color-sidebar-background: #1e293b;
  --color-sidebar-background-border: #334155;
  --color-brand-primary: #f1f5f9;
  --color-brand-content: #cbd5e1;
  --color-accent: #60a5fa;
  --color-accent-2: #3b82f6;
  --color-link: #60a5fa;
  --color-link--hover: #93c5fd;
  --color-inline-code-background: #334155;
  --color-highlighted-background: #374151;
  --color-highlighted-text: #fbbf24;
  --color-admonition-background: #1e293b;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">NeuroScope 0.1.0</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><div class="sidebar-brand">
  <a href="index.html">
    <img src="_static/favicon.svg" class="sidebar-logo" alt="NeuroScope" />
    <span class="sidebar-brand-text">
      NeuroScope
      <div class="sidebar-brand-version">0.1.0</div>
    </span>
  </a>
</div><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Advanced Usage Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="technical_deep_dive.html">Technical Deep Dive: Neural Network Diagnostics</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization_gallery.html">Visualization Gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributor Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="codeofconduct.html">Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/ahmadrazacdx/neuro-scope/releases">Changelog</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="https://github.com/ahmadrazacdx/neuro-scope/blob/main/docs/reference.md?plain=true" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div><div class="edit-this-page">
  <a class="muted-link" href="https://github.com/ahmadrazacdx/neuro-scope/edit/main/docs/reference.md" rel="edit" title="Edit this page">
    <svg><use href="#svg-pencil"></use></svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section class="tex2jax_ignore mathjax_ignore" id="api-reference">
<h1>API Reference<a class="headerlink" href="#api-reference" title="Link to this heading">¶</a></h1>
<p>Complete reference for all NeuroScope modules, classes, and functions.</p>
<section id="core-module">
<h2>Core Module<a class="headerlink" href="#core-module" title="Link to this heading">¶</a></h2>
<section id="module-neuroscope">
<span id="neuroscope"></span><h3>neuroscope<a class="headerlink" href="#module-neuroscope" title="Link to this heading">¶</a></h3>
<p>NeuroScope: A comprehensive neural network framework for learning and prototyping.</p>
<p>NeuroScope provides a clean, education-oriented interface for building and analyzing
multi-layer perceptrons with advanced diagnostic capabilities. Designed for rapid
experimentation with comprehensive monitoring and visualization tools.</p>
<dl class="simple">
<dt>Core Components:</dt><dd><ul class="simple">
<li><p>MLP: Modern multi-layer perceptron implementation</p></li>
<li><p>Diagnostics: Pre-training, training, and post-training analysis tools</p></li>
<li><p>Visualization: Publication-quality plotting and analysis</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">neuroscope.mlp</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLP</span><span class="p">,</span> <span class="n">mse</span><span class="p">,</span> <span class="n">accuracy_binary</span><span class="p">,</span> <span class="n">relu</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">neuroscope.diagnostics</span><span class="w"> </span><span class="kn">import</span> <span class="n">PreTrainingAnalyzer</span><span class="p">,</span> <span class="n">TrainingMonitor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">neuroscope.viz</span><span class="w"> </span><span class="kn">import</span> <span class="n">Visualizer</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create and train model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">out_activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Analyze before training</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">PreTrainingAnalyzer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">analyzer</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Ultra-fast training for production</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_fast</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Or train with full diagnostics for research</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">monitor</span> <span class="o">=</span> <span class="n">TrainingMonitor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="n">monitor</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Use functions directly</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_binary</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Visualize results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span> <span class="o">=</span> <span class="n">Visualizer</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_learning_curves</span><span class="p">()</span>
</pre></div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.MLP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">MLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'leaky_relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smart'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'normal'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.MLP" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Multi-layer perceptron for quick prototyping and experimentation.</p>
<p>This MLP supports arbitrary layer sizes, multiple activation functions,
and modern optimization techniques. Use <cite>compile</cite> to set hyperparameters
and <cite>fit</cite> to train the model. Includes comprehensive training monitoring
and diagnostic capabilities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer_dims</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence[int]</span></code>) – Sizes of layers including input &amp; output, e.g. [784, 128, 10].</p></li>
<li><p><strong>hidden_activation</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Activation function name for hidden layers.
Options: “relu”, “leaky_relu”, “tanh”, “sigmoid”, “selu”. Defaults to “leaky_relu”.</p></li>
<li><p><strong>out_activation</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Output activation function.
Options: “sigmoid” (binary), “softmax” (multiclass), None (regression). Defaults to None.</p></li>
<li><p><strong>init_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Weight initialization strategy.
Options: “smart”, “he”, “xavier”, “random”, “selu_init”. Defaults to “smart”.</p></li>
<li><p><strong>init_seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Random seed for reproducible weight initialization. Defaults to 42.</p></li>
<li><p><strong>dropout_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Dropout probability for hidden layers (0.0-1.0). Defaults to 0.0.</p></li>
<li><p><strong>dropout_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Dropout variant (“normal”, “alpha”). Defaults to “normal”.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.MLP.weights">
<span class="sig-name descname"><span class="pre">weights</span></span><a class="headerlink" href="#neuroscope.MLP.weights" title="Link to this definition">¶</a></dt>
<dd><p>Internal weight matrices for each layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list[NDArray[np.float64]]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.MLP.biases">
<span class="sig-name descname"><span class="pre">biases</span></span><a class="headerlink" href="#neuroscope.MLP.biases" title="Link to this definition">¶</a></dt>
<dd><p>Internal bias vectors for each layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list[NDArray[np.float64]]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.MLP.compiled">
<span class="sig-name descname"><span class="pre">compiled</span></span><a class="headerlink" href="#neuroscope.MLP.compiled" title="Link to this definition">¶</a></dt>
<dd><p>Whether the model has been compiled for training.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">neuroscope.mlp</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLP</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">out_activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.MLP.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'leaky_relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smart'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'normal'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.MLP.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.MLP.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'adam'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.compile"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.MLP.compile" title="Link to this definition">¶</a></dt>
<dd><p>Configure the model for training.</p>
<p>Sets up the optimizer, learning rate, regularization, and other training
hyperparameters. Must be called before training the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Optimization algorithm (“sgd”, “adam”). Defaults to “adam”.</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Learning rate for parameter updates. Defaults to 0.001.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Regularization type (“l2”, None). Defaults to None.</p></li>
<li><p><strong>lamda</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Regularization strength (lambda parameter). Defaults to 0.01.</p></li>
<li><p><strong>gradient_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Maximum gradient norm for clipping. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If invalid optimizer is specified.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="s2">&quot;l2&quot;</span><span class="p">,</span> <span class="n">lamda</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.MLP.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smart'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">binary_thresh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.MLP.evaluate" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate model performance on given data.</p>
<p>Computes loss and evaluation metric on the provided dataset.
Automatically selects appropriate loss function based on output activation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input data of shape (N, input_dim).</p></li>
<li><p><strong>y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Target values of shape (N,) or (N, output_dim).</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Evaluation metric (“smart”, “accuracy”, “mse”, “rmse”,
“mae”, “r2”, “f1”, “precision”, “recall”). Defaults to “smart”.</p></li>
<li><p><strong>binary_thresh</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Threshold for binary classification. Defaults to 0.5.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(loss, metric_score) where metric_score depends on the metric type.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.MLP.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numerical_check_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smart'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_before_training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.MLP.fit" title="Link to this definition">¶</a></dt>
<dd><p>Train the neural network on provided data.</p>
<p>Implements full training loop with support for validation, early stopping,
learning rate decay, and comprehensive monitoring. Returns detailed training
history and statistics for analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_train</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Training input data of shape (N, input_dim).</p></li>
<li><p><strong>y_train</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Training targets of shape (N,) or (N, output_dim).</p></li>
<li><p><strong>X_val</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>, <em>optional</em>) – Validation input data. Defaults to None.</p></li>
<li><p><strong>y_val</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>, <em>optional</em>) – Validation targets. Defaults to None.</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Number of training epochs. Defaults to 10.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Mini-batch size. If None, uses full batch. Defaults to None.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to print training progress. Defaults to True.</p></li>
<li><p><strong>log_every</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Frequency of progress logging in epochs. Defaults to 1.</p></li>
<li><p><strong>early_stopping_patience</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Epochs to wait for improvement before stopping.
Defaults to 50.</p></li>
<li><p><strong>lr_decay</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Learning rate decay factor per epoch. Defaults to None.</p></li>
<li><p><strong>numerical_check_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Frequency of numerical stability checks. Defaults to 100.</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Evaluation metric for monitoring. Defaults to “smart”.</p></li>
<li><p><strong>reset_before_training</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to reset weights before training. Defaults to True.</p></li>
<li><p><strong>monitor</strong> (<a class="reference internal" href="#neuroscope.TrainingMonitor" title="neuroscope.TrainingMonitor"><code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingMonitor</span></code></a>, <em>optional</em>) – Real-time training monitor. Defaults to None.</p></li>
<li><p><strong>monitor_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Monitoring frequency in epochs. Defaults to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Comprehensive training results containing:</dt><dd><ul class="simple">
<li><p>weights: Final trained weight matrices</p></li>
<li><p>biases: Final trained bias vectors</p></li>
<li><p>history: Training/validation loss and metrics per epoch</p></li>
<li><p>activations: Sample activations from middle epoch</p></li>
<li><p>gradients: Sample gradients from middle epoch</p></li>
<li><p>weight_stats_over_epochs: Weight statistics evolution</p></li>
<li><p>activation_stats_over_epochs: Activation statistics evolution</p></li>
<li><p>gradient_stats_over_epochs: Gradient statistics evolution</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If model is not compiled or if input dimensions are incompatible.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final training loss: </span><span class="si">{</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;history&#39;</span><span class="p">][</span><span class="s1">&#39;train_loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.MLP.fit_batch">
<span class="sig-name descname"><span class="pre">fit_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smart'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.fit_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.MLP.fit_batch" title="Link to this definition">¶</a></dt>
<dd><p>Train on a single batch for specified epochs. Uses 2-8 samples of given batch.
.. note:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">2</span><span class="o">-</span><span class="mi">8</span><span class="p">)</span> <span class="n">samples</span> <span class="ow">is</span> <span class="n">based</span> <span class="n">on</span> <span class="n">PyTorch</span> <span class="n">implementation</span> <span class="ow">and</span> <span class="n">literature</span> <span class="n">such</span> <span class="k">as</span>
<span class="n">blog</span> <span class="n">of</span> <span class="n">Karpathy</span> <span class="p">(</span><span class="n">A</span> <span class="n">Recipe</span> <span class="k">for</span> <span class="n">Training</span> <span class="n">Neural</span> <span class="n">Networks</span><span class="p">),</span> <span class="n">Universal</span> <span class="n">Approximation</span> <span class="n">Theorem</span> <span class="p">(</span><span class="n">Hornik</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span><span class="p">,</span> <span class="mi">1989</span><span class="p">),</span>
<span class="n">Empirical</span> <span class="n">Risk</span> <span class="n">Minimization</span> <span class="p">(</span><span class="n">Vapnik</span><span class="p">,</span> <span class="mi">1998</span><span class="p">)</span> <span class="ow">and</span> <span class="n">others</span><span class="o">.</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.MLP.fit_fast">
<span class="sig-name descname"><span class="pre">fit_fast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numerical_check_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smart'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_before_training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.fit_fast"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.MLP.fit_fast" title="Link to this definition">¶</a></dt>
<dd><p>High-performance training method optimized for fast training.</p>
<p>Ultra-fast training loop that eliminates statistics collection overhead
and monitoring bottlenecks. Provides 10-100x speedup over standard fit()
while maintaining identical API and training quality.</p>
<p>Key Performance Optimizations:
- Eliminates expensive statistics collection (main bottleneck)
- Uses optimized batch processing with array views
- Streamlined training loop with only essential operations
- Configurable evaluation frequency to reduce overhead</p>
<p>Expected Performance:
- 10-100x faster than fit() method
- 60-80% less memory usage</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_train</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Training input data of shape (N, input_dim).</p></li>
<li><p><strong>y_train</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Training targets of shape (N,) or (N, output_dim).</p></li>
<li><p><strong>X_val</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>, <em>optional</em>) – Validation input data. Defaults to None.</p></li>
<li><p><strong>y_val</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>, <em>optional</em>) – Validation targets. Defaults to None.</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Number of training epochs. Defaults to 10.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Mini-batch size. If None, uses full batch. Defaults to None.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to print training progress. Defaults to True.</p></li>
<li><p><strong>log_every</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Frequency of progress logging in epochs. Defaults to 1.</p></li>
<li><p><strong>early_stopping_patience</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Epochs to wait for improvement before stopping.
Defaults to 50.</p></li>
<li><p><strong>lr_decay</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Learning rate decay factor per epoch. Defaults to None.</p></li>
<li><p><strong>numerical_check_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Frequency of numerical stability checks. Defaults to 100.</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Evaluation metric for monitoring. Defaults to “smart”.</p></li>
<li><p><strong>reset_before_training</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to reset weights before training. Defaults to True.</p></li>
<li><p><strong>monitor</strong> (<a class="reference internal" href="#neuroscope.TrainingMonitor" title="neuroscope.TrainingMonitor"><code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingMonitor</span></code></a>, <em>optional</em>) – Real-time training monitor. Defaults to None.</p></li>
<li><p><strong>monitor_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Monitoring frequency in epochs. Defaults to 1.</p></li>
<li><p><strong>eval_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Evaluation frequency in epochs for performance. Defaults to 5.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Streamlined training results containing:</dt><dd><ul class="simple">
<li><p>weights: Final trained weight matrices</p></li>
<li><p>biases: Final trained bias vectors</p></li>
<li><p>history: Training/validation loss and metrics per epoch</p></li>
<li><p>performance_stats: Training time and speed metrics</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If model is not compiled or if input dimensions are incompatible.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Ultra-fast training</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_fast</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">eval_freq</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For research and debugging with full diagnostics, use the standard fit() method.
This method prioritizes speed over detailed monitoring capabilities.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.MLP.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.MLP.predict" title="Link to this definition">¶</a></dt>
<dd><p>Generate predictions for input samples.</p>
<p>Performs forward propagation through the network without dropout
to generate predictions on new data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input data of shape (N, input_dim).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Model predictions of shape (N, output_dim).</dt><dd><p>For regression: continuous values.
For binary classification: probabilities (0-1).
For multiclass: class probabilities.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>NDArray[np.float64]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary_preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>  <span class="c1"># For binary classification</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.MLP.reset_all">
<span class="sig-name descname"><span class="pre">reset_all</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.reset_all"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.MLP.reset_all" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.MLP.reset_optimizer">
<span class="sig-name descname"><span class="pre">reset_optimizer</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.reset_optimizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.MLP.reset_optimizer" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.MLP.reset_weights">
<span class="sig-name descname"><span class="pre">reset_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.reset_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.MLP.reset_weights" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.PreTrainingAnalyzer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">PreTrainingAnalyzer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PreTrainingAnalyzer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Comprehensive pre-training diagnostic tool for neural networks.</p>
<p>Analyzes model architecture, weight initialization, and data compatibility
before training begins. Implements research-validated checks to identify
potential training issues early, based on established deep learning principles
from Glorot &amp; Bengio (2010), He et al. (2015), and others.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – Compiled MLP model instance with initialized weights.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.PreTrainingAnalyzer.model">
<span class="sig-name descname"><span class="pre">model</span></span><a class="headerlink" href="#neuroscope.PreTrainingAnalyzer.model" title="Link to this definition">¶</a></dt>
<dd><p>Reference to the neural network model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.PreTrainingAnalyzer.results">
<span class="sig-name descname"><span class="pre">results</span></span><a class="headerlink" href="#neuroscope.PreTrainingAnalyzer.results" title="Link to this definition">¶</a></dt>
<dd><p>Cached analysis results.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a></p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">neuroscope.diagnostics</span><span class="w"> </span><span class="kn">import</span> <span class="n">PreTrainingAnalyzer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">PreTrainingAnalyzer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize analyzer with a compiled model.</p>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PreTrainingAnalyzer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PreTrainingAnalyzer.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize analyzer with a compiled model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PreTrainingAnalyzer.analyze">
<span class="sig-name descname"><span class="pre">analyze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PreTrainingAnalyzer.analyze" title="Link to this definition">¶</a></dt>
<dd><p>Comprehensive pre-training analysis with clean tabular output.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PreTrainingAnalyzer.analyze_architecture_sanity">
<span class="sig-name descname"><span class="pre">analyze_architecture_sanity</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze_architecture_sanity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PreTrainingAnalyzer.analyze_architecture_sanity" title="Link to this definition">¶</a></dt>
<dd><p>Perform comprehensive architecture validation.</p>
<p>Validates network architecture against established deep learning principles
and best practices. Checks for common architectural pitfalls such as
incompatible activation functions, inappropriate depth, and problematic
layer configurations based on research findings.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Analysis results containing:</dt><dd><ul class="simple">
<li><p>issues: List of critical architectural problems</p></li>
<li><p>warnings: List of potential concerns</p></li>
<li><p>status: Overall architecture quality (“PASS”, “WARN”, “FAIL”)</p></li>
<li><p>note: Summary diagnostic message</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Based on research from Bengio et al. (2009) on vanishing gradients,
modern best practices for deep architectures, and activation function
compatibility studies.</p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze_architecture_sanity</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;issues&#39;</span><span class="p">]:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Critical issues found:&quot;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;issues&#39;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PreTrainingAnalyzer.analyze_capacity_data_ratio">
<span class="sig-name descname"><span class="pre">analyze_capacity_data_ratio</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze_capacity_data_ratio"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PreTrainingAnalyzer.analyze_capacity_data_ratio" title="Link to this definition">¶</a></dt>
<dd><p>Analyze parameter count relative to training data size.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PreTrainingAnalyzer.analyze_convergence_feasibility">
<span class="sig-name descname"><span class="pre">analyze_convergence_feasibility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze_convergence_feasibility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PreTrainingAnalyzer.analyze_convergence_feasibility" title="Link to this definition">¶</a></dt>
<dd><p>Assess whether the current setup can theoretically converge.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PreTrainingAnalyzer.analyze_initial_loss">
<span class="sig-name descname"><span class="pre">analyze_initial_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze_initial_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PreTrainingAnalyzer.analyze_initial_loss" title="Link to this definition">¶</a></dt>
<dd><p>Validate initial loss against theoretical expectations.</p>
<p>Compares the model’s initial loss (before training) with theoretical
baselines for different task types. For classification, expects loss
near -log(1/num_classes). For regression, compares against variance-based
baseline as described in Goodfellow et al. (2016).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input data of shape (N, input_dim).</p></li>
<li><p><strong>y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Target values of shape (N,) or (N, output_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Analysis results containing:</dt><dd><ul class="simple">
<li><p>initial_loss: Computed initial loss value</p></li>
<li><p>expected_loss: Theoretical expected loss</p></li>
<li><p>ratio: initial_loss / expected_loss</p></li>
<li><p>task_type: Detected task type (regression/classification)</p></li>
<li><p>status: “PASS”, “WARN”, or “FAIL”</p></li>
<li><p>note: Diagnostic message</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze_initial_loss</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial loss check: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;status&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PreTrainingAnalyzer.analyze_layer_capacity">
<span class="sig-name descname"><span class="pre">analyze_layer_capacity</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze_layer_capacity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PreTrainingAnalyzer.analyze_layer_capacity" title="Link to this definition">¶</a></dt>
<dd><p>Analyze information bottlenecks and layer capacity issues.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PreTrainingAnalyzer.analyze_weight_init">
<span class="sig-name descname"><span class="pre">analyze_weight_init</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze_weight_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PreTrainingAnalyzer.analyze_weight_init" title="Link to this definition">¶</a></dt>
<dd><p>Validate weight initialization against theoretical optima.</p>
<p>Analyzes weight initialization quality by comparing actual weight standard
deviations against theoretically optimal values for different activation
functions. Based on He initialization (He et al. 2015) for ReLU variants
and Xavier initialization (Glorot &amp; Bengio 2010) for sigmoid/tanh.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Analysis results containing:</dt><dd><ul class="simple">
<li><p>layers: List of per-layer initialization analysis</p></li>
<li><p>status: Overall initialization quality (“PASS”, “WARN”, “FAIL”)</p></li>
<li><p>note: Summary diagnostic message</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze_weight_init</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;layers&#39;</span><span class="p">]:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Layer </span><span class="si">{</span><span class="n">layer</span><span class="p">[</span><span class="s1">&#39;layer&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">layer</span><span class="p">[</span><span class="s1">&#39;status&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">TrainingMonitor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">history_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Comprehensive real-time training monitoring system for neural networks.</p>
<p>Monitors 10 key training health indicators:
- Dead ReLU neurons detection
- Vanishing Gradient Problem (VGP) detection
- Exploding Gradient Problem (EGP) detection
- Weight health analysis
- Learning progress
- Overfitting detection
- Gradient signal-to-noise ratio
- Activation saturation detection (tanh/sigmoid)
- Training plateau detection
- Weight update vs magnitude ratios</p>
<p>Initialize comprehensive training monitor.</p>
<p>Sets up monitoring infrastructure for tracking 10 key training health
indicators during neural network training. Uses research-validated
thresholds and emoji-based status visualization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Optional MLP model instance (can be set later).</p></li>
<li><p><strong>history_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Number of epochs to keep in rolling
history for trend analysis. Defaults to 50.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">monitor</span> <span class="o">=</span> <span class="n">TrainingMonitor</span><span class="p">(</span><span class="n">history_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="n">monitor</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">history_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize comprehensive training monitor.</p>
<p>Sets up monitoring infrastructure for tracking 10 key training health
indicators during neural network training. Uses research-validated
thresholds and emoji-based status visualization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Optional MLP model instance (can be set later).</p></li>
<li><p><strong>history_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Number of epochs to keep in rolling
history for trend analysis. Defaults to 50.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">monitor</span> <span class="o">=</span> <span class="n">TrainingMonitor</span><span class="p">(</span><span class="n">history_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="n">monitor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.format_monitoring_output">
<span class="sig-name descname"><span class="pre">format_monitoring_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">results</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.format_monitoring_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.format_monitoring_output" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.monitor_activation_saturation">
<span class="sig-name descname"><span class="pre">monitor_activation_saturation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">activations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_functions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_activation_saturation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.monitor_activation_saturation" title="Link to this definition">¶</a></dt>
<dd><p>Research-accurate activation saturation detection.
Based on Glorot &amp; Bengio (2010), Hochreiter (1991), and He et al. (2015).
Key insights:
- Saturation = extreme activation values + poor gradient flow + skewed distributions
- Uses function-specific thresholds and statistical distribution analysis
- Tracks saturation propagation through network layers
:param activations: List of activation arrays from each layer
:param activation_functions: List of activation function names for each layer</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (saturation_score, emoji_status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.monitor_exploding_gradients">
<span class="sig-name descname"><span class="pre">monitor_exploding_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradients</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_exploding_gradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.monitor_exploding_gradients" title="Link to this definition">¶</a></dt>
<dd><p>Detect exploding gradient problem using gradient norm analysis.</p>
<p>Monitors gradient magnitudes to detect exploding gradients based on
research by Pascanu et al. (2013). Uses both global norm and per-layer
analysis to identify unstable training dynamics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>gradients</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[NDArray[np.float64]]</span></code>) – Gradient arrays for each layer.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>(egp_severity, status_emoji) where:</dt><dd><ul class="simple">
<li><p>egp_severity: Float in [0,1] indicating severity</p></li>
<li><p>status: 🟢 (stable), 🟡 (elevated), 🔴 (exploding)</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Based on “On the difficulty of training recurrent neural networks”
(Pascanu et al. 2013) gradient clipping and norm analysis.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.monitor_gradient_snr">
<span class="sig-name descname"><span class="pre">monitor_gradient_snr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradients</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_gradient_snr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.monitor_gradient_snr" title="Link to this definition">¶</a></dt>
<dd><p>Calculate Gradient Signal-to-Noise Ratio (GSNR) for optimization health.
- Signal: RMS gradient magnitude (update strength)
- Noise: Coefficient of variation (relative inconsistency)
- GSNR = RMS_magnitude / (std_magnitude + ε)
This measures gradient update consistency.
:param gradients: List of gradient arrays from each layer</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (gsnr_score, emoji_status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.monitor_learning_progress">
<span class="sig-name descname"><span class="pre">monitor_learning_progress</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">current_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_learning_progress"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.monitor_learning_progress" title="Link to this definition">¶</a></dt>
<dd><p>Research-accurate learning progress monitor.
Based on optimization literature: Bottou (2010), Goodfellow et al. (2016), Smith (2017).
Key insights:
- Progress = consistent loss reduction + convergence stability + generalization health
- Uses exponential moving averages and plateau detection from literature
:param current_loss: Current training loss
:param val_loss: Optional validation loss</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (progress_score, emoji_status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.monitor_overfitting">
<span class="sig-name descname"><span class="pre">monitor_overfitting</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_overfitting"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.monitor_overfitting" title="Link to this definition">¶</a></dt>
<dd><p>Research-accurate overfitting detection.
Based on Prechelt (1998), Goodfellow et al. (2016), and Caruana et al. (2001).
Key insights:
- Overfitting = increasing generalization gap + validation curve deterioration
:param train_loss: Training loss
:param val_loss: Validation loss</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (overfitting_score, emoji_status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.monitor_plateau">
<span class="sig-name descname"><span class="pre">monitor_plateau</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">current_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_gradients</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_plateau"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.monitor_plateau" title="Link to this definition">¶</a></dt>
<dd><p>Research-accurate training plateau detection.
Based on Prechelt (1998), Bengio (2012), and Smith (2017).
Key insights:
- Plateau = statistical stagnation + loss of learning momentum + gradient analysis
- Uses multi-scale analysis and statistical significance testing
- Integrates validation correlation and gradient magnitude trends
:param current_loss: Current training loss
:param val_loss: Optional validation loss for correlation analysis
:param current_gradients: Optional gradient arrays for gradient-based detection</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (plateau_score, emoji_status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.monitor_relu_dead_neurons">
<span class="sig-name descname"><span class="pre">monitor_relu_dead_neurons</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">activations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_functions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_relu_dead_neurons"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.monitor_relu_dead_neurons" title="Link to this definition">¶</a></dt>
<dd><p>Monitor for dead ReLU neurons during training.</p>
<p>Detects neurons that have become inactive (always output zero) which
indicates the “dying ReLU” problem. Uses activation-function-aware
thresholds based on research by Glorot et al. (2011) and He et al. (2015).</p>
<p>Natural sparsity in ReLU networks is expected (~50%), but excessive
sparsity (&gt;90%) indicates dead neurons that cannot learn.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>activations</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[NDArray[np.float64]]</span></code>) – Layer activation outputs.</p></li>
<li><p><strong>activation_functions</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[str]</span></code>, <em>optional</em>) – Activation function names per layer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>(dead_percentage, status_emoji) where status is:</dt><dd><ul class="simple">
<li><p>🟢: Healthy sparsity (&lt;10% dead)</p></li>
<li><p>🟡: Moderate concern (10-30% dead)</p></li>
<li><p>🔴: Critical issue (&gt;30% dead)</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Based on “Deep Sparse Rectifier Neural Networks” (Glorot et al. 2011)
and “Delving Deep into Rectifiers” (He et al. 2015).</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.monitor_step">
<span class="sig-name descname"><span class="pre">monitor_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradients</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_updates</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_functions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.monitor_step" title="Link to this definition">¶</a></dt>
<dd><p>Perform one monitoring step and return all metrics.
:param epoch: Current epoch number
:param train_loss: Training loss
:param val_loss: Validation loss (optional)
:param activations: Layer activations (optional)
:param gradients: Layer gradients (optional)
:param weights: Layer weights (optional)
:param weight_updates: Weight updates (optional)
:param activation_functions: List of activation function names (optional)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dictionary containing all monitoring results</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.monitor_vanishing_gradients">
<span class="sig-name descname"><span class="pre">monitor_vanishing_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradients</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_vanishing_gradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.monitor_vanishing_gradients" title="Link to this definition">¶</a></dt>
<dd><p>Detect vanishing gradient problem using research-validated metrics.</p>
<p>Monitors gradient flow through the network to detect vanishing gradients
based on variance analysis from Glorot &amp; Bengio (2010). Healthy networks
maintain similar gradient variance across layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>gradients</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[NDArray[np.float64]]</span></code>) – Gradient arrays for each layer.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>(vgp_severity, status_emoji) where:</dt><dd><ul class="simple">
<li><p>vgp_severity: Float in [0,1] indicating severity</p></li>
<li><p>status: 🟢 (healthy), 🟡 (warning), 🔴 (critical)</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Implementation based on “Understanding the difficulty of training
deep feedforward neural networks” (Glorot &amp; Bengio 2010).</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.monitor_weight_health">
<span class="sig-name descname"><span class="pre">monitor_weight_health</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_weight_health"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.monitor_weight_health" title="Link to this definition">¶</a></dt>
<dd><p>Simple, research-backed weight health monitor.
Based on Glorot &amp; Bengio (2010) and He et al. (2015) initialization theory.
:param weights: List of weight matrices</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (health_score, status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.monitor_weight_update_ratio">
<span class="sig-name descname"><span class="pre">monitor_weight_update_ratio</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_updates</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_weight_update_ratio"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.monitor_weight_update_ratio" title="Link to this definition">¶</a></dt>
<dd><p>Monitor Weight Update to Weight magnitude Ratios (WUR) for learning rate validation.
Research-based implementation using:
- Smith (2015): Learning rate should produce WUR ~10^-3 to 10^-2 for stable training
- Zeiler (2012): Update magnitude should be proportional to weight magnitude
Formula: WUR = ||weight_update|| / ||weight|| per layer
:param weights: Current weight matrices
:param weight_updates: Weight update matrices (gradients * learning_rate)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (median_wur, status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.TrainingMonitor.reset_history">
<span class="sig-name descname"><span class="pre">reset_history</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.reset_history"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.TrainingMonitor.reset_history" title="Link to this definition">¶</a></dt>
<dd><p>Reset all monitoring history.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.PostTrainingEvaluator">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">PostTrainingEvaluator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/posttraining.html#PostTrainingEvaluator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PostTrainingEvaluator" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Comprehensive post-training evaluation system for neural networks.</p>
<p>Provides thorough analysis of trained model performance including robustness
testing, performance metrics evaluation, and diagnostic assessments. Designed
to validate model quality and identify potential deployment issues after
training completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – Trained and compiled MLP model instance with initialized weights.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.PostTrainingEvaluator.model">
<span class="sig-name descname"><span class="pre">model</span></span><a class="headerlink" href="#neuroscope.PostTrainingEvaluator.model" title="Link to this definition">¶</a></dt>
<dd><p>Reference to the trained neural network model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.PostTrainingEvaluator.results">
<span class="sig-name descname"><span class="pre">results</span></span><a class="headerlink" href="#neuroscope.PostTrainingEvaluator.results" title="Link to this definition">¶</a></dt>
<dd><p>Cached evaluation results from various assessments.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a></p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">neuroscope.diagnostics</span><span class="w"> </span><span class="kn">import</span> <span class="n">PostTrainingEvaluator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span> <span class="o">=</span> <span class="n">PostTrainingEvaluator</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Access detailed results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">robustness</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate_robustness</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">performance</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate_performance</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize evaluator with a trained model.</p>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PostTrainingEvaluator.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/posttraining.html#PostTrainingEvaluator.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PostTrainingEvaluator.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize evaluator with a trained model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PostTrainingEvaluator.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/posttraining.html#PostTrainingEvaluator.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PostTrainingEvaluator.evaluate" title="Link to this definition">¶</a></dt>
<dd><p>Run comprehensive model evaluation and generate summary report.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PostTrainingEvaluator.evaluate_performance">
<span class="sig-name descname"><span class="pre">evaluate_performance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/posttraining.html#PostTrainingEvaluator.evaluate_performance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PostTrainingEvaluator.evaluate_performance" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate model performance metrics.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PostTrainingEvaluator.evaluate_robustness">
<span class="sig-name descname"><span class="pre">evaluate_robustness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_levels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/posttraining.html#PostTrainingEvaluator.evaluate_robustness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PostTrainingEvaluator.evaluate_robustness" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate model robustness against Gaussian noise.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.PostTrainingEvaluator.evaluate_stability">
<span class="sig-name descname"><span class="pre">evaluate_stability</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/posttraining.html#PostTrainingEvaluator.evaluate_stability"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.PostTrainingEvaluator.evaluate_stability" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate prediction stability across similar inputs. (K Neighbor Approach)</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.Visualizer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">Visualizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hist</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.Visualizer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>High quality visualization tool for neural network training analysis.</p>
<p>Provides comprehensive plotting capabilities for analyzing training dynamics,
network behavior, and diagnostic information. Creates professional-grade
figures suitable for research publications and presentations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hist</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>) – Complete training history from model.fit() containing:
- history: Training/validation metrics per epoch
- weights/biases: Final network parameters
- activations/gradients: Sample network internals
- <a href="#id1"><span class="problematic" id="id2">*</span></a>_stats_over_epochs: Statistical evolution during training</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.Visualizer.hist">
<span class="sig-name descname"><span class="pre">hist</span></span><a class="headerlink" href="#neuroscope.Visualizer.hist" title="Link to this definition">¶</a></dt>
<dd><p>Complete training history data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.Visualizer.history">
<span class="sig-name descname"><span class="pre">history</span></span><a class="headerlink" href="#neuroscope.Visualizer.history" title="Link to this definition">¶</a></dt>
<dd><p>Training metrics (loss, accuracy) evolution.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">weights/biases</span></span></dt>
<dd><p>Final network parameters.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">activations/gradients</span></span></dt>
<dd><p>Representative network internals.</p>
</dd></dl>

<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">neuroscope.viz</span><span class="w"> </span><span class="kn">import</span> <span class="n">Visualizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span> <span class="o">=</span> <span class="n">Visualizer</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_learning_curves</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_activation_distribution</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_gradient_flow</span><span class="p">()</span>
</pre></div>
</div>
<p>Initialize visualizer with comprehensive training history.</p>
<p>Sets up visualization infrastructure and applies publication-quality
styling to all plots. Automatically extracts relevant data components
for different types of analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hist</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>) – Training history from model.fit() containing all
training statistics, network states, and diagnostic information.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.Visualizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hist</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.Visualizer.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize visualizer with comprehensive training history.</p>
<p>Sets up visualization infrastructure and applies publication-quality
styling to all plots. Automatically extracts relevant data components
for different types of analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hist</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>) – Training history from model.fit() containing all
training statistics, network states, and diagnostic information.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.Visualizer.plot_activation_hist">
<span class="sig-name descname"><span class="pre">plot_activation_hist</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(9,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kde</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_activation_hist"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.Visualizer.plot_activation_hist" title="Link to this definition">¶</a></dt>
<dd><p>Plot activation value distributions across network layers.</p>
<p>Visualizes the distribution of activation values for each layer at a specific
epoch, aggregated from all mini-batches. Useful for detecting activation
saturation, dead neurons, and distribution shifts during training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Specific epoch to plot. If None, uses last epoch. Defaults to None.</p></li>
<li><p><strong>figsize</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple[int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int]</span></code>, <em>optional</em>) – Figure dimensions. Defaults to (9, 4).</p></li>
<li><p><strong>kde</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to use KDE-style smoothing for smoother curves. Defaults to False.</p></li>
<li><p><strong>last_layer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to include output layer. Defaults to False.</p></li>
<li><p><strong>save_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Path to save the figure. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_activation_hist</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;activations.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.Visualizer.plot_activation_stats">
<span class="sig-name descname"><span class="pre">plot_activation_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">activation_stats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(12,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_activation_stats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.Visualizer.plot_activation_stats" title="Link to this definition">¶</a></dt>
<dd><p>Plot activation statistics over time with both mean and std.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>activation_stats</strong> – Dict of layer activation stats OR None to use class data
Format: {‘layer_0’: {‘mean’: […], ‘std’: […]}, …}</p></li>
<li><p><strong>figsize</strong> – Figure size tuple</p></li>
<li><p><strong>save_path</strong> – Path to save figure</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.Visualizer.plot_gradient_hist">
<span class="sig-name descname"><span class="pre">plot_gradient_hist</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(9,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kde</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_gradient_hist"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.Visualizer.plot_gradient_hist" title="Link to this definition">¶</a></dt>
<dd><p>Plot gradient value distributions across network layers.</p>
<p>Visualizes gradient distributions to detect vanishing/exploding gradient
problems, gradient flow issues, and training stability. Shows zero-line
reference for assessing gradient symmetry and magnitude.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Specific epoch to plot. If None, uses last epoch. Defaults to None.</p></li>
<li><p><strong>figsize</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple[int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int]</span></code>, <em>optional</em>) – Figure dimensions. Defaults to (9, 4).</p></li>
<li><p><strong>kde</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to use KDE-style smoothing. Defaults to False.</p></li>
<li><p><strong>last_layer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to include output layer gradients. Defaults to False.</p></li>
<li><p><strong>save_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Path to save the figure. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Gradient distributions should be roughly symmetric around zero for healthy training.
Very narrow distributions may indicate vanishing gradients, while very wide
distributions may indicate exploding gradients.</p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_gradient_hist</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;gradients.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.Visualizer.plot_gradient_norms">
<span class="sig-name descname"><span class="pre">plot_gradient_norms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradient_norms</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(12,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_gradient_norms"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.Visualizer.plot_gradient_norms" title="Link to this definition">¶</a></dt>
<dd><p>Plot gradient norms per layer over epochs.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.Visualizer.plot_gradient_stats">
<span class="sig-name descname"><span class="pre">plot_gradient_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(12,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_gradient_stats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.Visualizer.plot_gradient_stats" title="Link to this definition">¶</a></dt>
<dd><p>Plot gradient statistics over time with both mean and std.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.Visualizer.plot_learning_curves">
<span class="sig-name descname"><span class="pre">plot_learning_curves</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(9,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ci</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">markers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'accuracy'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_learning_curves"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.Visualizer.plot_learning_curves" title="Link to this definition">¶</a></dt>
<dd><p>Plot training and validation learning curves.</p>
<p>Creates publication-quality subplot showing loss and metric evolution
during training. Automatically detects available data and applies
consistent styling with optional confidence intervals.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>figsize</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple[int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int]</span></code>, <em>optional</em>) – Figure dimensions (width, height). Defaults to (9, 4).</p></li>
<li><p><strong>ci</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to add confidence intervals using moving window statistics.
Defaults to False.</p></li>
<li><p><strong>markers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to show markers on line plots. Defaults to True.</p></li>
<li><p><strong>save_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Path to save the figure. Defaults to None.</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Name of the metric for y-axis label. Defaults to ‘accuracy’.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_learning_curves</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">ci</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;curves.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.Visualizer.plot_training_animation">
<span class="sig-name descname"><span class="pre">plot_training_animation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'dark'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_training_animation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.Visualizer.plot_training_animation" title="Link to this definition">¶</a></dt>
<dd><p>Creates a comprehensive 4-panel GIF animation showing:
1. Loss curves over time
2. Accuracy curves over time
3. Current metrics bar chart
4. Gradient flow analysis
Speed automatically adjusts based on epoch count for smooth motion feel.
:param bg: Theme (‘dark’ or ‘light’)
:param save_path: Path to save GIF (defaults to ‘mlp_training_animation.gif’)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Path to saved GIF file</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.Visualizer.plot_update_ratios">
<span class="sig-name descname"><span class="pre">plot_update_ratios</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">update_ratios</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(12,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_update_ratios"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.Visualizer.plot_update_ratios" title="Link to this definition">¶</a></dt>
<dd><p>Plot weight update ratios per layer across epochs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>update_ratios</strong> – Dict of layer update ratios (optional - uses collected data if None)
Format: {‘layer_0’: [ratio_epoch_0, ratio_epoch_1, …], …}</p></li>
<li><p><strong>figsize</strong> – Figure size tuple</p></li>
<li><p><strong>save_path</strong> – Path to save figure</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.Visualizer.plot_weight_hist">
<span class="sig-name descname"><span class="pre">plot_weight_hist</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(9,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kde</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_weight_hist"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.Visualizer.plot_weight_hist" title="Link to this definition">¶</a></dt>
<dd><p>Uses aggregated samples from all mini-batches within
an epoch to create representative distributions. Shows weight evolution patterns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> – Specific epoch to plot (default: last epoch)</p></li>
<li><p><strong>figsize</strong> – Figure size tuple</p></li>
<li><p><strong>kde</strong> – Whether to use KDE-style smoothing</p></li>
<li><p><strong>last_layer</strong> – Whether to include output layer (default: False, hidden layers only)</p></li>
<li><p><strong>save_path</strong> – Path to save figure</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.Visualizer.plot_weight_stats">
<span class="sig-name descname"><span class="pre">plot_weight_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(12,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_weight_stats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.Visualizer.plot_weight_stats" title="Link to this definition">¶</a></dt>
<dd><p>Plot weight statistics over time with both mean and std.</p>
</dd></dl>

</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.PTA">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">PTA</span></span><a class="headerlink" href="#neuroscope.PTA" title="Link to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer" title="neuroscope.diagnostics.pretraining.PreTrainingAnalyzer"><code class="xref py py-class docutils literal notranslate"><span class="pre">PreTrainingAnalyzer</span></code></a></p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.TM">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">TM</span></span><a class="headerlink" href="#neuroscope.TM" title="Link to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor" title="neuroscope.diagnostics.training_monitors.TrainingMonitor"><code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingMonitor</span></code></a></p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.PTE">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">PTE</span></span><a class="headerlink" href="#neuroscope.PTE" title="Link to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator" title="neuroscope.diagnostics.posttraining.PostTrainingEvaluator"><code class="xref py py-class docutils literal notranslate"><span class="pre">PostTrainingEvaluator</span></code></a></p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.VIZ">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">VIZ</span></span><a class="headerlink" href="#neuroscope.VIZ" title="Link to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#neuroscope.viz.plots.Visualizer" title="neuroscope.viz.plots.Visualizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Visualizer</span></code></a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.mse">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">mse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.mse" title="Link to this definition">¶</a></dt>
<dd><p>Compute mean squared error loss.</p>
<p>Standard regression loss function that penalizes squared differences
between predictions and targets. Suitable for continuous target values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Ground truth values of shape (N,) or (N, 1).</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted values of shape (N,) or (N, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Mean squared error loss (scalar).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">LossFunctions</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.bce">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">bce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.bce" title="Link to this definition">¶</a></dt>
<dd><p>Compute binary cross-entropy loss.</p>
<p>Standard loss function for binary classification problems. Applies
numerical clipping to prevent log(0) errors and ensure stability.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Binary labels (0/1) of shape (N,).</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted probabilities of shape (N,).</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Small value for numerical stability. Defaults to 1e-12.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Binary cross-entropy loss (scalar).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">LossFunctions</span><span class="o">.</span><span class="n">bce</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BCE Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.cce">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">cce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.cce" title="Link to this definition">¶</a></dt>
<dd><p>Compute categorical cross-entropy loss.</p>
<p>Standard loss function for multi-class classification. Handles both
sparse labels (class indices) and one-hot encoded targets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Class labels of shape (N,) for sparse labels
or (N, C) for one-hot encoded targets.</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted class probabilities of shape (N, C).</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Small value for numerical stability. Defaults to 1e-12.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Categorical cross-entropy loss (scalar).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">LossFunctions</span><span class="o">.</span><span class="n">cce</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CCE Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.mse_with_reg">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">mse_with_reg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.mse_with_reg" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.bce_with_reg">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">bce_with_reg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.bce_with_reg" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.cce_with_reg">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">cce_with_reg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.cce_with_reg" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.accuracy_binary">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">accuracy_binary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.accuracy_binary" title="Link to this definition">¶</a></dt>
<dd><p>Compute binary classification accuracy.</p>
<p>Calculates the fraction of correctly predicted samples for binary
classification by applying a threshold to predicted probabilities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Binary labels (0/1) of shape (N,) or (N, 1).</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted probabilities of shape (N,) or (N, 1).</p></li>
<li><p><strong>thresh</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Classification threshold. Defaults to 0.5.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Binary classification accuracy as a fraction (0.0 to 1.0).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">Metrics</span><span class="o">.</span><span class="n">accuracy_binary</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Binary Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.accuracy_multiclass">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">accuracy_multiclass</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.accuracy_multiclass" title="Link to this definition">¶</a></dt>
<dd><p>Compute multi-class classification accuracy.</p>
<p>Calculates the fraction of correctly predicted samples for multi-class
classification problems. Handles both sparse labels and one-hot encoded inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – True class labels of shape (N,) for sparse labels
or (N, C) for one-hot encoded.</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted class probabilities of shape (N, C).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Classification accuracy as a fraction (0.0 to 1.0).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">Metrics</span><span class="o">.</span><span class="n">accuracy_multiclass</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.rmse">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">rmse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.rmse" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.mae">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">mae</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.mae" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.r2_score">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">r2_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.r2_score" title="Link to this definition">¶</a></dt>
<dd><p>Compute coefficient of determination (R² score).</p>
<p>Measures the proportion of variance in the dependent variable that is
predictable from the independent variables. R² = 1 indicates perfect fit,
R² = 0 indicates the model performs as well as predicting the mean.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Ground truth values of shape (N,) or (N, 1).</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted values of shape (N,) or (N, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>R² score (can be negative for very poor fits).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">r2</span> <span class="o">=</span> <span class="n">Metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R² Score: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.f1_score">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">f1_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'weighted'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.f1_score" title="Link to this definition">¶</a></dt>
<dd><p>Compute F1 score: 2 * (Precision * Recall) / (Precision + Recall)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> – True labels</p></li>
<li><p><strong>y_pred</strong> – Predicted probabilities or labels</p></li>
<li><p><strong>average</strong> – ‘macro’, ‘weighted’, or None for per-class scores</p></li>
<li><p><strong>threshold</strong> – Decision threshold for binary classification</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.precision">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'weighted'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.precision" title="Link to this definition">¶</a></dt>
<dd><p>Compute precision score: TP / (TP + FP)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> – True labels</p></li>
<li><p><strong>y_pred</strong> – Predicted probabilities or labels</p></li>
<li><p><strong>average</strong> – ‘macro’, ‘weighted’, or None for per-class scores</p></li>
<li><p><strong>threshold</strong> – Decision threshold for binary classification</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.recall">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">recall</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'weighted'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.recall" title="Link to this definition">¶</a></dt>
<dd><p>Compute recall score: TP / (TP + FN)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> – True labels</p></li>
<li><p><strong>y_pred</strong> – Predicted probabilities or labels</p></li>
<li><p><strong>average</strong> – ‘macro’, ‘weighted’, or None for per-class scores</p></li>
<li><p><strong>threshold</strong> – Decision threshold for binary classification</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.relu">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">relu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.relu" title="Link to this definition">¶</a></dt>
<dd><p>Compute ReLU (Rectified Linear Unit) activation.</p>
<p>Applies the rectified linear activation function that outputs the input
for positive values and zero for negative values. Most popular activation
for hidden layers in modern neural networks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input array of any shape.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ReLU-activated values (non-negative).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>NDArray[np.float64]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">activated</span> <span class="o">=</span> <span class="n">ActivationFunctions</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Negative values become 0, positive values unchanged</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.leaky_relu">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">leaky_relu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">negative_slope</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.leaky_relu" title="Link to this definition">¶</a></dt>
<dd><p>Compute Leaky ReLU activation function.</p>
<p>Variant of ReLU that allows small negative values to flow through,
helping to mitigate the “dying ReLU” problem where neurons can become
permanently inactive.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input array of any shape.</p></li>
<li><p><strong>negative_slope</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Slope for negative values. Defaults to 0.01.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Leaky ReLU-activated values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>NDArray[np.float64]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">activated</span> <span class="o">=</span> <span class="n">ActivationFunctions</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Positive values unchanged, negative values scaled by 0.01</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.sigmoid">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">sigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.sigmoid" title="Link to this definition">¶</a></dt>
<dd><p>Compute sigmoid activation function.</p>
<p>Applies the logistic sigmoid function that maps input to (0, 1) range.
Includes numerical clipping to prevent overflow in exponential computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input array of any shape.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Sigmoid-activated values in range (0, 1).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>NDArray[np.float64]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">activated</span> <span class="o">=</span> <span class="n">ActivationFunctions</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Values are now between 0 and 1</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.tanh">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">tanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.tanh" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.selu">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">selu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.selu" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.softmax">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.softmax" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.he_init">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">he_init</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.he_init" title="Link to this definition">¶</a></dt>
<dd><p>He initialization for ReLU and ReLU-variant activations.</p>
<p>Optimal for ReLU-based networks as derived in He et al. (2015).
Uses standard deviation of sqrt(2/fan_in) to maintain proper
variance propagation through ReLU activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer_dims</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[int]</span></code>) – Layer dimensions [input_dim, hidden_dim, …, output_dim].</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Random seed for reproducibility. Defaults to 42.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>(weights, biases) where weights are initialized</dt><dd><p>according to He initialization and biases are zero-initialized.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Based on “Delving Deep into Rectifiers: Surpassing Human-Level
Performance on ImageNet Classification” (He et al. 2015).</p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span><span class="p">,</span> <span class="n">biases</span> <span class="o">=</span> <span class="n">WeightInits</span><span class="o">.</span><span class="n">he_init</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.xavier_init">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">xavier_init</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.xavier_init" title="Link to this definition">¶</a></dt>
<dd><p>Xavier/Glorot initialization for sigmoid and tanh activations.</p>
<p>Optimal for symmetric activations like tanh and sigmoid. Uses
standard deviation of sqrt(2/(fan_in + fan_out)) to maintain
constant variance across layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer_dims</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[int]</span></code>) – Layer dimensions [input_dim, hidden_dim, …, output_dim].</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Random seed for reproducibility. Defaults to 42.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(weights, biases) with Xavier-initialized weights and zero biases.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Based on “Understanding the difficulty of training deep feedforward
neural networks” (Glorot &amp; Bengio 2010).</p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span><span class="p">,</span> <span class="n">biases</span> <span class="o">=</span> <span class="n">WeightInits</span><span class="o">.</span><span class="n">xavier_init</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.random_init">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">random_init</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.random_init" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neuroscope.selu_init">
<span class="sig-prename descclassname"><span class="pre">neuroscope.</span></span><span class="sig-name descname"><span class="pre">selu_init</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neuroscope.selu_init" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</section>
</section>
<section id="mlp-module">
<h2>MLP Module<a class="headerlink" href="#mlp-module" title="Link to this heading">¶</a></h2>
<section id="module-neuroscope.mlp.mlp">
<span id="multi-layer-perceptron"></span><h3>Multi-Layer Perceptron<a class="headerlink" href="#module-neuroscope.mlp.mlp" title="Link to this heading">¶</a></h3>
<p>MLP Neural Network
Main neural network class integrating all framework components.</p>
<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.mlp.mlp.</span></span><span class="sig-name descname"><span class="pre">MLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'leaky_relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smart'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'normal'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.mlp.MLP" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Multi-layer perceptron for quick prototyping and experimentation.</p>
<p>This MLP supports arbitrary layer sizes, multiple activation functions,
and modern optimization techniques. Use <cite>compile</cite> to set hyperparameters
and <cite>fit</cite> to train the model. Includes comprehensive training monitoring
and diagnostic capabilities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer_dims</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence[int]</span></code>) – Sizes of layers including input &amp; output, e.g. [784, 128, 10].</p></li>
<li><p><strong>hidden_activation</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Activation function name for hidden layers.
Options: “relu”, “leaky_relu”, “tanh”, “sigmoid”, “selu”. Defaults to “leaky_relu”.</p></li>
<li><p><strong>out_activation</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Output activation function.
Options: “sigmoid” (binary), “softmax” (multiclass), None (regression). Defaults to None.</p></li>
<li><p><strong>init_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Weight initialization strategy.
Options: “smart”, “he”, “xavier”, “random”, “selu_init”. Defaults to “smart”.</p></li>
<li><p><strong>init_seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Random seed for reproducible weight initialization. Defaults to 42.</p></li>
<li><p><strong>dropout_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Dropout probability for hidden layers (0.0-1.0). Defaults to 0.0.</p></li>
<li><p><strong>dropout_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Dropout variant (“normal”, “alpha”). Defaults to “normal”.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.weights">
<span class="sig-name descname"><span class="pre">weights</span></span><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.weights" title="Link to this definition">¶</a></dt>
<dd><p>Internal weight matrices for each layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list[NDArray[np.float64]]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.biases">
<span class="sig-name descname"><span class="pre">biases</span></span><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.biases" title="Link to this definition">¶</a></dt>
<dd><p>Internal bias vectors for each layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list[NDArray[np.float64]]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.compiled">
<span class="sig-name descname"><span class="pre">compiled</span></span><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.compiled" title="Link to this definition">¶</a></dt>
<dd><p>Whether the model has been compiled for training.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a></p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">neuroscope.mlp</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLP</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">out_activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'leaky_relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smart'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'normal'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.reset_weights">
<span class="sig-name descname"><span class="pre">reset_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.reset_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.reset_weights" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.reset_optimizer">
<span class="sig-name descname"><span class="pre">reset_optimizer</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.reset_optimizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.reset_optimizer" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.reset_all">
<span class="sig-name descname"><span class="pre">reset_all</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.reset_all"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.reset_all" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'adam'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.compile"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.compile" title="Link to this definition">¶</a></dt>
<dd><p>Configure the model for training.</p>
<p>Sets up the optimizer, learning rate, regularization, and other training
hyperparameters. Must be called before training the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Optimization algorithm (“sgd”, “adam”). Defaults to “adam”.</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Learning rate for parameter updates. Defaults to 0.001.</p></li>
<li><p><strong>reg</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Regularization type (“l2”, None). Defaults to None.</p></li>
<li><p><strong>lamda</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Regularization strength (lambda parameter). Defaults to 0.01.</p></li>
<li><p><strong>gradient_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Maximum gradient norm for clipping. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If invalid optimizer is specified.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="s2">&quot;l2&quot;</span><span class="p">,</span> <span class="n">lamda</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.predict" title="Link to this definition">¶</a></dt>
<dd><p>Generate predictions for input samples.</p>
<p>Performs forward propagation through the network without dropout
to generate predictions on new data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input data of shape (N, input_dim).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Model predictions of shape (N, output_dim).</dt><dd><p>For regression: continuous values.
For binary classification: probabilities (0-1).
For multiclass: class probabilities.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>NDArray[np.float64]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary_preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>  <span class="c1"># For binary classification</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smart'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">binary_thresh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.evaluate" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate model performance on given data.</p>
<p>Computes loss and evaluation metric on the provided dataset.
Automatically selects appropriate loss function based on output activation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input data of shape (N, input_dim).</p></li>
<li><p><strong>y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Target values of shape (N,) or (N, output_dim).</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Evaluation metric (“smart”, “accuracy”, “mse”, “rmse”,
“mae”, “r2”, “f1”, “precision”, “recall”). Defaults to “smart”.</p></li>
<li><p><strong>binary_thresh</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Threshold for binary classification. Defaults to 0.5.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(loss, metric_score) where metric_score depends on the metric type.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numerical_check_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smart'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_before_training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.fit" title="Link to this definition">¶</a></dt>
<dd><p>Train the neural network on provided data.</p>
<p>Implements full training loop with support for validation, early stopping,
learning rate decay, and comprehensive monitoring. Returns detailed training
history and statistics for analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_train</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Training input data of shape (N, input_dim).</p></li>
<li><p><strong>y_train</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Training targets of shape (N,) or (N, output_dim).</p></li>
<li><p><strong>X_val</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>, <em>optional</em>) – Validation input data. Defaults to None.</p></li>
<li><p><strong>y_val</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>, <em>optional</em>) – Validation targets. Defaults to None.</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Number of training epochs. Defaults to 10.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Mini-batch size. If None, uses full batch. Defaults to None.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to print training progress. Defaults to True.</p></li>
<li><p><strong>log_every</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Frequency of progress logging in epochs. Defaults to 1.</p></li>
<li><p><strong>early_stopping_patience</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Epochs to wait for improvement before stopping.
Defaults to 50.</p></li>
<li><p><strong>lr_decay</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Learning rate decay factor per epoch. Defaults to None.</p></li>
<li><p><strong>numerical_check_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Frequency of numerical stability checks. Defaults to 100.</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Evaluation metric for monitoring. Defaults to “smart”.</p></li>
<li><p><strong>reset_before_training</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to reset weights before training. Defaults to True.</p></li>
<li><p><strong>monitor</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingMonitor</span></code>, <em>optional</em>) – Real-time training monitor. Defaults to None.</p></li>
<li><p><strong>monitor_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Monitoring frequency in epochs. Defaults to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Comprehensive training results containing:</dt><dd><ul class="simple">
<li><p>weights: Final trained weight matrices</p></li>
<li><p>biases: Final trained bias vectors</p></li>
<li><p>history: Training/validation loss and metrics per epoch</p></li>
<li><p>activations: Sample activations from middle epoch</p></li>
<li><p>gradients: Sample gradients from middle epoch</p></li>
<li><p>weight_stats_over_epochs: Weight statistics evolution</p></li>
<li><p>activation_stats_over_epochs: Activation statistics evolution</p></li>
<li><p>gradient_stats_over_epochs: Gradient statistics evolution</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If model is not compiled or if input dimensions are incompatible.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final training loss: </span><span class="si">{</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;history&#39;</span><span class="p">][</span><span class="s1">&#39;train_loss&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.fit_fast">
<span class="sig-name descname"><span class="pre">fit_fast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping_patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numerical_check_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smart'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_before_training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.fit_fast"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.fit_fast" title="Link to this definition">¶</a></dt>
<dd><p>High-performance training method optimized for fast training.</p>
<p>Ultra-fast training loop that eliminates statistics collection overhead
and monitoring bottlenecks. Provides 10-100x speedup over standard fit()
while maintaining identical API and training quality.</p>
<p>Key Performance Optimizations:
- Eliminates expensive statistics collection (main bottleneck)
- Uses optimized batch processing with array views
- Streamlined training loop with only essential operations
- Configurable evaluation frequency to reduce overhead</p>
<p>Expected Performance:
- 10-100x faster than fit() method
- 60-80% less memory usage</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X_train</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Training input data of shape (N, input_dim).</p></li>
<li><p><strong>y_train</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Training targets of shape (N,) or (N, output_dim).</p></li>
<li><p><strong>X_val</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>, <em>optional</em>) – Validation input data. Defaults to None.</p></li>
<li><p><strong>y_val</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>, <em>optional</em>) – Validation targets. Defaults to None.</p></li>
<li><p><strong>epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Number of training epochs. Defaults to 10.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Mini-batch size. If None, uses full batch. Defaults to None.</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to print training progress. Defaults to True.</p></li>
<li><p><strong>log_every</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Frequency of progress logging in epochs. Defaults to 1.</p></li>
<li><p><strong>early_stopping_patience</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Epochs to wait for improvement before stopping.
Defaults to 50.</p></li>
<li><p><strong>lr_decay</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Learning rate decay factor per epoch. Defaults to None.</p></li>
<li><p><strong>numerical_check_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Frequency of numerical stability checks. Defaults to 100.</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Evaluation metric for monitoring. Defaults to “smart”.</p></li>
<li><p><strong>reset_before_training</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to reset weights before training. Defaults to True.</p></li>
<li><p><strong>monitor</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingMonitor</span></code>, <em>optional</em>) – Real-time training monitor. Defaults to None.</p></li>
<li><p><strong>monitor_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Monitoring frequency in epochs. Defaults to 1.</p></li>
<li><p><strong>eval_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Evaluation frequency in epochs for performance. Defaults to 5.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Streamlined training results containing:</dt><dd><ul class="simple">
<li><p>weights: Final trained weight matrices</p></li>
<li><p>biases: Final trained bias vectors</p></li>
<li><p>history: Training/validation loss and metrics per epoch</p></li>
<li><p>performance_stats: Training time and speed metrics</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If model is not compiled or if input dimensions are incompatible.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Ultra-fast training</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_fast</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">eval_freq</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For research and debugging with full diagnostics, use the standard fit() method.
This method prioritizes speed over detailed monitoring capabilities.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.mlp.MLP.fit_batch">
<span class="sig-name descname"><span class="pre">fit_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'smart'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/mlp.html#MLP.fit_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.mlp.MLP.fit_batch" title="Link to this definition">¶</a></dt>
<dd><p>Train on a single batch for specified epochs. Uses 2-8 samples of given batch.
.. note:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">2</span><span class="o">-</span><span class="mi">8</span><span class="p">)</span> <span class="n">samples</span> <span class="ow">is</span> <span class="n">based</span> <span class="n">on</span> <span class="n">PyTorch</span> <span class="n">implementation</span> <span class="ow">and</span> <span class="n">literature</span> <span class="n">such</span> <span class="k">as</span>
<span class="n">blog</span> <span class="n">of</span> <span class="n">Karpathy</span> <span class="p">(</span><span class="n">A</span> <span class="n">Recipe</span> <span class="k">for</span> <span class="n">Training</span> <span class="n">Neural</span> <span class="n">Networks</span><span class="p">),</span> <span class="n">Universal</span> <span class="n">Approximation</span> <span class="n">Theorem</span> <span class="p">(</span><span class="n">Hornik</span> <span class="n">et</span> <span class="n">al</span><span class="o">.</span><span class="p">,</span> <span class="mi">1989</span><span class="p">),</span>
<span class="n">Empirical</span> <span class="n">Risk</span> <span class="n">Minimization</span> <span class="p">(</span><span class="n">Vapnik</span><span class="p">,</span> <span class="mi">1998</span><span class="p">)</span> <span class="ow">and</span> <span class="n">others</span><span class="o">.</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-neuroscope.mlp.activations">
<span id="activation-functions"></span><h3>Activation Functions<a class="headerlink" href="#module-neuroscope.mlp.activations" title="Link to this heading">¶</a></h3>
<p>Activation Functions Module
A comprehensive collection of activation functions and their derivatives for neural networks.</p>
<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.mlp.activations.</span></span><span class="sig-name descname"><span class="pre">ActivationFunctions</span></span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Comprehensive collection of activation functions and their derivatives.</p>
<p>Provides implementations of popular activation functions used in neural networks,
including their derivatives for backpropagation. All functions are numerically
stable and handle edge cases appropriately.</p>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.sigmoid">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.sigmoid"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.sigmoid" title="Link to this definition">¶</a></dt>
<dd><p>Compute sigmoid activation function.</p>
<p>Applies the logistic sigmoid function that maps input to (0, 1) range.
Includes numerical clipping to prevent overflow in exponential computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input array of any shape.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Sigmoid-activated values in range (0, 1).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>NDArray[np.float64]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">activated</span> <span class="o">=</span> <span class="n">ActivationFunctions</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Values are now between 0 and 1</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.sigmoid_derivative">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sigmoid_derivative</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.sigmoid_derivative"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.sigmoid_derivative" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.softmax">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.softmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.softmax" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.tanh">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.tanh"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.tanh" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.tanh_derivative">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tanh_derivative</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.tanh_derivative"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.tanh_derivative" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.relu">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">relu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.relu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.relu" title="Link to this definition">¶</a></dt>
<dd><p>Compute ReLU (Rectified Linear Unit) activation.</p>
<p>Applies the rectified linear activation function that outputs the input
for positive values and zero for negative values. Most popular activation
for hidden layers in modern neural networks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input array of any shape.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ReLU-activated values (non-negative).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>NDArray[np.float64]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">activated</span> <span class="o">=</span> <span class="n">ActivationFunctions</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Negative values become 0, positive values unchanged</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.relu_derivative">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">relu_derivative</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.relu_derivative"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.relu_derivative" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.leaky_relu">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">leaky_relu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">negative_slope</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.leaky_relu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.leaky_relu" title="Link to this definition">¶</a></dt>
<dd><p>Compute Leaky ReLU activation function.</p>
<p>Variant of ReLU that allows small negative values to flow through,
helping to mitigate the “dying ReLU” problem where neurons can become
permanently inactive.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input array of any shape.</p></li>
<li><p><strong>negative_slope</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Slope for negative values. Defaults to 0.01.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Leaky ReLU-activated values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>NDArray[np.float64]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">activated</span> <span class="o">=</span> <span class="n">ActivationFunctions</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Positive values unchanged, negative values scaled by 0.01</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.leaky_relu_derivative">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">leaky_relu_derivative</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">negative_slope</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.leaky_relu_derivative"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.leaky_relu_derivative" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.selu">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">selu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.selu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.selu" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.selu_derivative">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">selu_derivative</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.selu_derivative"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.selu_derivative" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.inverted_dropout">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">inverted_dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.inverted_dropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.inverted_dropout" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.activations.ActivationFunctions.alpha_dropout">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">alpha_dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/activations.html#ActivationFunctions.alpha_dropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.activations.ActivationFunctions.alpha_dropout" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-neuroscope.mlp.losses">
<span id="loss-functions"></span><h3>Loss Functions<a class="headerlink" href="#module-neuroscope.mlp.losses" title="Link to this heading">¶</a></h3>
<p>Loss Functions Module
Collection of loss functions for different machine learning tasks.</p>
<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.mlp.losses.LossFunctions">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.mlp.losses.</span></span><span class="sig-name descname"><span class="pre">LossFunctions</span></span><a class="reference internal" href="_modules/neuroscope/mlp/losses.html#LossFunctions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.losses.LossFunctions" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Collection of loss functions for neural network training.</p>
<p>Provides implementations of common loss functions used in regression and
classification tasks, with support for L2 regularization. All functions
handle numerical stability and edge cases appropriately.</p>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.losses.LossFunctions.mse">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/losses.html#LossFunctions.mse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.losses.LossFunctions.mse" title="Link to this definition">¶</a></dt>
<dd><p>Compute mean squared error loss.</p>
<p>Standard regression loss function that penalizes squared differences
between predictions and targets. Suitable for continuous target values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Ground truth values of shape (N,) or (N, 1).</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted values of shape (N,) or (N, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Mean squared error loss (scalar).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">LossFunctions</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.losses.LossFunctions.bce">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/losses.html#LossFunctions.bce"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.losses.LossFunctions.bce" title="Link to this definition">¶</a></dt>
<dd><p>Compute binary cross-entropy loss.</p>
<p>Standard loss function for binary classification problems. Applies
numerical clipping to prevent log(0) errors and ensure stability.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Binary labels (0/1) of shape (N,).</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted probabilities of shape (N,).</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Small value for numerical stability. Defaults to 1e-12.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Binary cross-entropy loss (scalar).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">LossFunctions</span><span class="o">.</span><span class="n">bce</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BCE Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.losses.LossFunctions.bce_with_reg">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bce_with_reg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/losses.html#LossFunctions.bce_with_reg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.losses.LossFunctions.bce_with_reg" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.losses.LossFunctions.cce">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/losses.html#LossFunctions.cce"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.losses.LossFunctions.cce" title="Link to this definition">¶</a></dt>
<dd><p>Compute categorical cross-entropy loss.</p>
<p>Standard loss function for multi-class classification. Handles both
sparse labels (class indices) and one-hot encoded targets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Class labels of shape (N,) for sparse labels
or (N, C) for one-hot encoded targets.</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted class probabilities of shape (N, C).</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Small value for numerical stability. Defaults to 1e-12.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Categorical cross-entropy loss (scalar).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">LossFunctions</span><span class="o">.</span><span class="n">cce</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CCE Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.losses.LossFunctions.cce_with_reg">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cce_with_reg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-12</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/losses.html#LossFunctions.cce_with_reg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.losses.LossFunctions.cce_with_reg" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.losses.LossFunctions.mse_with_reg">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mse_with_reg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/losses.html#LossFunctions.mse_with_reg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.losses.LossFunctions.mse_with_reg" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-neuroscope.mlp.metrics">
<span id="metrics"></span><h3>Metrics<a class="headerlink" href="#module-neuroscope.mlp.metrics" title="Link to this heading">¶</a></h3>
<p>Metrics Module
Comprehensive evaluation metrics for regression and classification tasks.</p>
<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.mlp.metrics.Metrics">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.mlp.metrics.</span></span><span class="sig-name descname"><span class="pre">Metrics</span></span><a class="reference internal" href="_modules/neuroscope/mlp/metrics.html#Metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.metrics.Metrics" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Comprehensive collection of evaluation metrics for neural networks.</p>
<p>Provides implementations of standard metrics for both regression and
classification tasks. All metrics handle edge cases and provide
meaningful results for model evaluation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.metrics.Metrics.accuracy_multiclass">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">accuracy_multiclass</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/metrics.html#Metrics.accuracy_multiclass"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.metrics.Metrics.accuracy_multiclass" title="Link to this definition">¶</a></dt>
<dd><p>Compute multi-class classification accuracy.</p>
<p>Calculates the fraction of correctly predicted samples for multi-class
classification problems. Handles both sparse labels and one-hot encoded inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – True class labels of shape (N,) for sparse labels
or (N, C) for one-hot encoded.</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted class probabilities of shape (N, C).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Classification accuracy as a fraction (0.0 to 1.0).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">Metrics</span><span class="o">.</span><span class="n">accuracy_multiclass</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.metrics.Metrics.accuracy_binary">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">accuracy_binary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/metrics.html#Metrics.accuracy_binary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.metrics.Metrics.accuracy_binary" title="Link to this definition">¶</a></dt>
<dd><p>Compute binary classification accuracy.</p>
<p>Calculates the fraction of correctly predicted samples for binary
classification by applying a threshold to predicted probabilities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Binary labels (0/1) of shape (N,) or (N, 1).</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted probabilities of shape (N,) or (N, 1).</p></li>
<li><p><strong>thresh</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Classification threshold. Defaults to 0.5.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Binary classification accuracy as a fraction (0.0 to 1.0).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">Metrics</span><span class="o">.</span><span class="n">accuracy_binary</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Binary Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.metrics.Metrics.mse">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/metrics.html#Metrics.mse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.metrics.Metrics.mse" title="Link to this definition">¶</a></dt>
<dd><p>Compute mean squared error metric.</p>
<p>Calculates the average squared differences between predicted and true values.
Commonly used metric for regression problems.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Ground truth values of shape (N,) or (N, 1).</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted values of shape (N,) or (N, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Mean squared error (scalar).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mse_score</span> <span class="o">=</span> <span class="n">Metrics</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MSE: </span><span class="si">{</span><span class="n">mse_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.metrics.Metrics.rmse">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">rmse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/metrics.html#Metrics.rmse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.metrics.Metrics.rmse" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.metrics.Metrics.mae">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mae</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/metrics.html#Metrics.mae"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.metrics.Metrics.mae" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.metrics.Metrics.r2_score">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">r2_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/metrics.html#Metrics.r2_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.metrics.Metrics.r2_score" title="Link to this definition">¶</a></dt>
<dd><p>Compute coefficient of determination (R² score).</p>
<p>Measures the proportion of variance in the dependent variable that is
predictable from the independent variables. R² = 1 indicates perfect fit,
R² = 0 indicates the model performs as well as predicting the mean.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Ground truth values of shape (N,) or (N, 1).</p></li>
<li><p><strong>y_pred</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Predicted values of shape (N,) or (N, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>R² score (can be negative for very poor fits).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">r2</span> <span class="o">=</span> <span class="n">Metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R² Score: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.metrics.Metrics.precision">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'weighted'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/metrics.html#Metrics.precision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.metrics.Metrics.precision" title="Link to this definition">¶</a></dt>
<dd><p>Compute precision score: TP / (TP + FP)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> – True labels</p></li>
<li><p><strong>y_pred</strong> – Predicted probabilities or labels</p></li>
<li><p><strong>average</strong> – ‘macro’, ‘weighted’, or None for per-class scores</p></li>
<li><p><strong>threshold</strong> – Decision threshold for binary classification</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.metrics.Metrics.recall">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">recall</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'weighted'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/metrics.html#Metrics.recall"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.metrics.Metrics.recall" title="Link to this definition">¶</a></dt>
<dd><p>Compute recall score: TP / (TP + FN)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> – True labels</p></li>
<li><p><strong>y_pred</strong> – Predicted probabilities or labels</p></li>
<li><p><strong>average</strong> – ‘macro’, ‘weighted’, or None for per-class scores</p></li>
<li><p><strong>threshold</strong> – Decision threshold for binary classification</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.metrics.Metrics.f1_score">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">f1_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'weighted'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/metrics.html#Metrics.f1_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.metrics.Metrics.f1_score" title="Link to this definition">¶</a></dt>
<dd><p>Compute F1 score: 2 * (Precision * Recall) / (Precision + Recall)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> – True labels</p></li>
<li><p><strong>y_pred</strong> – Predicted probabilities or labels</p></li>
<li><p><strong>average</strong> – ‘macro’, ‘weighted’, or None for per-class scores</p></li>
<li><p><strong>threshold</strong> – Decision threshold for binary classification</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-neuroscope.mlp.initializers">
<span id="weight-initializers"></span><h3>Weight Initializers<a class="headerlink" href="#module-neuroscope.mlp.initializers" title="Link to this heading">¶</a></h3>
<p>Weight Initialization Module
Professional weight initialization strategies for neural networks.</p>
<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.mlp.initializers.WeightInits">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.mlp.initializers.</span></span><span class="sig-name descname"><span class="pre">WeightInits</span></span><a class="reference internal" href="_modules/neuroscope/mlp/initializers.html#WeightInits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.initializers.WeightInits" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Research-validated weight initialization strategies for neural networks.</p>
<p>Provides implementations of modern weight initialization methods that
help maintain proper gradient flow and accelerate training convergence.
All methods follow established theoretical foundations from deep learning
research.</p>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.initializers.WeightInits.he_init">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">he_init</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/initializers.html#WeightInits.he_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.initializers.WeightInits.he_init" title="Link to this definition">¶</a></dt>
<dd><p>He initialization for ReLU and ReLU-variant activations.</p>
<p>Optimal for ReLU-based networks as derived in He et al. (2015).
Uses standard deviation of sqrt(2/fan_in) to maintain proper
variance propagation through ReLU activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer_dims</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[int]</span></code>) – Layer dimensions [input_dim, hidden_dim, …, output_dim].</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Random seed for reproducibility. Defaults to 42.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>(weights, biases) where weights are initialized</dt><dd><p>according to He initialization and biases are zero-initialized.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Based on “Delving Deep into Rectifiers: Surpassing Human-Level
Performance on ImageNet Classification” (He et al. 2015).</p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span><span class="p">,</span> <span class="n">biases</span> <span class="o">=</span> <span class="n">WeightInits</span><span class="o">.</span><span class="n">he_init</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.initializers.WeightInits.xavier_init">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">xavier_init</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/initializers.html#WeightInits.xavier_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.initializers.WeightInits.xavier_init" title="Link to this definition">¶</a></dt>
<dd><p>Xavier/Glorot initialization for sigmoid and tanh activations.</p>
<p>Optimal for symmetric activations like tanh and sigmoid. Uses
standard deviation of sqrt(2/(fan_in + fan_out)) to maintain
constant variance across layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer_dims</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[int]</span></code>) – Layer dimensions [input_dim, hidden_dim, …, output_dim].</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Random seed for reproducibility. Defaults to 42.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(weights, biases) with Xavier-initialized weights and zero biases.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Based on “Understanding the difficulty of training deep feedforward
neural networks” (Glorot &amp; Bengio 2010).</p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span><span class="p">,</span> <span class="n">biases</span> <span class="o">=</span> <span class="n">WeightInits</span><span class="o">.</span><span class="n">xavier_init</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.initializers.WeightInits.random_init">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">random_init</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/initializers.html#WeightInits.random_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.initializers.WeightInits.random_init" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.initializers.WeightInits.selu_init">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">selu_init</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/initializers.html#WeightInits.selu_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.initializers.WeightInits.selu_init" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.initializers.WeightInits.smart_init">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">smart_init</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'leaky_relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/initializers.html#WeightInits.smart_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.initializers.WeightInits.smart_init" title="Link to this definition">¶</a></dt>
<dd><p>Intelligent initialization selection based on activation function.</p>
<p>Automatically selects the optimal initialization strategy based on
the chosen activation function. Combines research-validated best
practices to ensure proper gradient flow from the start of training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer_dims</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[int]</span></code>) – Layer dimensions [input_dim, hidden_dim, …, output_dim].</p></li>
<li><p><strong>hidden_activation</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Hidden layer activation function. Defaults to ‘leaky_relu’.</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Random seed for reproducibility. Defaults to 42.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(weights, biases) with optimally initialized weights for the activation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>]</p>
</dd>
</dl>
<dl class="simple">
<dt>Initialization Strategy:</dt><dd><ul class="simple">
<li><p>ReLU/Leaky ReLU: He initialization</p></li>
<li><p>Tanh/Sigmoid: Xavier initialization</p></li>
<li><p>SELU: LeCun initialization</p></li>
<li><p>Unknown: Xavier initialization (safe default)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span><span class="p">,</span> <span class="n">biases</span> <span class="o">=</span> <span class="n">WeightInits</span><span class="o">.</span><span class="n">smart_init</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="s1">&#39;relu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-neuroscope.mlp.utils">
<span id="utilities"></span><h3>Utilities<a class="headerlink" href="#module-neuroscope.mlp.utils" title="Link to this heading">¶</a></h3>
<p>Utilities Module
Helper functions for training, validation, and data processing.</p>
<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.mlp.utils.Utils">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.mlp.utils.</span></span><span class="sig-name descname"><span class="pre">Utils</span></span><a class="reference internal" href="_modules/neuroscope/mlp/utils.html#Utils"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.utils.Utils" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Utility functions for neural network training and data processing.</p>
<p>Provides essential helper functions for batch processing, gradient clipping,
input validation, and numerical stability checks. All methods are static
and can be used independently throughout the framework.</p>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.utils.Utils.get_batches">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_batches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/utils.html#Utils.get_batches"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.utils.Utils.get_batches" title="Link to this definition">¶</a></dt>
<dd><p>Generate mini-batches for training.</p>
<p>Creates mini-batches from input data with optional shuffling for
stochastic gradient descent training. Handles the last batch even
if it contains fewer samples than batch_size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input data of shape (N, input_dim).</p></li>
<li><p><strong>y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Target data of shape (N,) or (N, output_dim).</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Size of each mini-batch. Defaults to 32.</p></li>
<li><p><strong>shuffle</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to shuffle data before batching. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple[NDArray</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray]</span></code> – (X_batch, y_batch) for each mini-batch.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">Utils</span><span class="o">.</span><span class="n">get_batches</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
<span class="gp">... </span>    <span class="c1"># Process batch</span>
<span class="gp">... </span>    <span class="k">pass</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.utils.Utils.get_batches_fast">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_batches_fast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/utils.html#Utils.get_batches_fast"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.utils.Utils.get_batches_fast" title="Link to this definition">¶</a></dt>
<dd><p>Generate mini-batches for training with optimized memory usage.
Expected to be 2-5x faster than get_batches() for large datasets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input data of shape (N, input_dim).</p></li>
<li><p><strong>y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Target data of shape (N,) or (N, output_dim).</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Size of each mini-batch. Defaults to 32.</p></li>
<li><p><strong>shuffle</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to shuffle data before batching. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple[NDArray</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray]</span></code> – (X_batch, y_batch) for each mini-batch.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Uses array views (slicing) instead of fancy indexing to avoid memory allocation.
Pre-reshapes y to avoid repeated reshaping in training loop.</p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Fast batch preprocessing for fast training</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">Utils</span><span class="o">.</span><span class="n">get_batches_fast</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
<span class="gp">... </span>    <span class="c1"># Process batch</span>
<span class="gp">... </span>    <span class="k">pass</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.utils.Utils.gradient_clipping">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">gradient_clipping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradients</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/utils.html#Utils.gradient_clipping"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.utils.Utils.gradient_clipping" title="Link to this definition">¶</a></dt>
<dd><p>Apply gradient clipping to prevent exploding gradients.</p>
<p>Clips gradients by global norm as described in Pascanu et al. (2013).
If the global norm exceeds max_norm, all gradients are scaled down
proportionally to maintain their relative magnitudes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gradients</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[NDArray[np.float64]]</span></code>) – List of gradient arrays.</p></li>
<li><p><strong>max_norm</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <em>optional</em>) – Maximum allowed gradient norm. Defaults to 5.0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Clipped gradient arrays.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>[NDArray[np.float64]]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Based on “On the difficulty of training recurrent neural networks”
(Pascanu et al. 2013) for gradient norm clipping.</p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clipped_grads</span> <span class="o">=</span> <span class="n">Utils</span><span class="o">.</span><span class="n">gradient_clipping</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">5.0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.utils.Utils.validate_array_input">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate_array_input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fast_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/utils.html#Utils.validate_array_input"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.utils.Utils.validate_array_input" title="Link to this definition">¶</a></dt>
<dd><p>Optimized validation for neural network operations.</p>
<p>Performs efficient validation with optional fast mode for training.
Automatically converts compatible inputs to numpy arrays when possible.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>arr</strong> – Input array or array-like object to validate.</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>) – Name of the array for error messages.</p></li>
<li><p><strong>min_dims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Minimum allowed dimensions. Defaults to 1.</p></li>
<li><p><strong>max_dims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Maximum allowed dimensions. Defaults to 3.</p></li>
<li><p><strong>fast_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Skip expensive NaN/inf checks for speed. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Validated numpy array.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>NDArray[np.float64]</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.13)"><strong>TypeError</strong></a> – If input cannot be converted to numpy array.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If dimensions, shape, or values are invalid.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_valid</span> <span class="o">=</span> <span class="n">Utils</span><span class="o">.</span><span class="n">validate_array_input</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s2">&quot;training_data&quot;</span><span class="p">,</span> <span class="n">min_dims</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_dims</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_fast</span> <span class="o">=</span> <span class="n">Utils</span><span class="o">.</span><span class="n">validate_array_input</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s2">&quot;X_train&quot;</span><span class="p">,</span> <span class="n">fast_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># For fit_fast()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.utils.Utils.validate_layer_dims">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate_layer_dims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/utils.html#Utils.validate_layer_dims"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.utils.Utils.validate_layer_dims" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.mlp.utils.Utils.check_numerical_stability">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">check_numerical_stability</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arrays</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'computation'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fast_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/mlp/utils.html#Utils.check_numerical_stability"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.mlp.utils.Utils.check_numerical_stability" title="Link to this definition">¶</a></dt>
<dd><p>Simple numerical stability check with user-friendly warnings.</p>
<p>Provides clear, actionable warnings for common training issues.
Fast mode only checks for critical problems for performance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>arrays</strong> – List of arrays to check for numerical issues.</p></li>
<li><p><strong>context</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Context description for error messages. Defaults to “computation”.</p></li>
<li><p><strong>fast_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Skip detailed checks for speed. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of simple, actionable issue descriptions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">issues</span> <span class="o">=</span> <span class="n">Utils</span><span class="o">.</span><span class="n">check_numerical_stability</span><span class="p">(</span><span class="n">activations</span><span class="p">,</span> <span class="s2">&quot;forward_pass&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">issues</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;⚠️ Training Issue: </span><span class="si">{</span><span class="n">issues</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="diagnostics-module">
<h2>Diagnostics Module<a class="headerlink" href="#diagnostics-module" title="Link to this heading">¶</a></h2>
<section id="module-neuroscope.diagnostics.pretraining">
<span id="pre-training-analysis"></span><h3>Pre-Training Analysis<a class="headerlink" href="#module-neuroscope.diagnostics.pretraining" title="Link to this heading">¶</a></h3>
<p>Pre-Training Analysis for NeuroScope MLP Framework
Focused pre-training analysis tools for neural network assessment before training.</p>
<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.diagnostics.pretraining.PreTrainingAnalyzer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.diagnostics.pretraining.</span></span><span class="sig-name descname"><span class="pre">PreTrainingAnalyzer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Comprehensive pre-training diagnostic tool for neural networks.</p>
<p>Analyzes model architecture, weight initialization, and data compatibility
before training begins. Implements research-validated checks to identify
potential training issues early, based on established deep learning principles
from Glorot &amp; Bengio (2010), He et al. (2015), and others.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – Compiled MLP model instance with initialized weights.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.model">
<span class="sig-name descname"><span class="pre">model</span></span><a class="headerlink" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.model" title="Link to this definition">¶</a></dt>
<dd><p>Reference to the neural network model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.results">
<span class="sig-name descname"><span class="pre">results</span></span><a class="headerlink" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.results" title="Link to this definition">¶</a></dt>
<dd><p>Cached analysis results.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a></p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">neuroscope.diagnostics</span><span class="w"> </span><span class="kn">import</span> <span class="n">PreTrainingAnalyzer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">PreTrainingAnalyzer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize analyzer with a compiled model.</p>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize analyzer with a compiled model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_initial_loss">
<span class="sig-name descname"><span class="pre">analyze_initial_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze_initial_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_initial_loss" title="Link to this definition">¶</a></dt>
<dd><p>Validate initial loss against theoretical expectations.</p>
<p>Compares the model’s initial loss (before training) with theoretical
baselines for different task types. For classification, expects loss
near -log(1/num_classes). For regression, compares against variance-based
baseline as described in Goodfellow et al. (2016).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Input data of shape (N, input_dim).</p></li>
<li><p><strong>y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">NDArray[np.float64]</span></code>) – Target values of shape (N,) or (N, output_dim).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Analysis results containing:</dt><dd><ul class="simple">
<li><p>initial_loss: Computed initial loss value</p></li>
<li><p>expected_loss: Theoretical expected loss</p></li>
<li><p>ratio: initial_loss / expected_loss</p></li>
<li><p>task_type: Detected task type (regression/classification)</p></li>
<li><p>status: “PASS”, “WARN”, or “FAIL”</p></li>
<li><p>note: Diagnostic message</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze_initial_loss</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial loss check: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;status&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_weight_init">
<span class="sig-name descname"><span class="pre">analyze_weight_init</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze_weight_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_weight_init" title="Link to this definition">¶</a></dt>
<dd><p>Validate weight initialization against theoretical optima.</p>
<p>Analyzes weight initialization quality by comparing actual weight standard
deviations against theoretically optimal values for different activation
functions. Based on He initialization (He et al. 2015) for ReLU variants
and Xavier initialization (Glorot &amp; Bengio 2010) for sigmoid/tanh.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Analysis results containing:</dt><dd><ul class="simple">
<li><p>layers: List of per-layer initialization analysis</p></li>
<li><p>status: Overall initialization quality (“PASS”, “WARN”, “FAIL”)</p></li>
<li><p>note: Summary diagnostic message</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze_weight_init</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;layers&#39;</span><span class="p">]:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Layer </span><span class="si">{</span><span class="n">layer</span><span class="p">[</span><span class="s1">&#39;layer&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">layer</span><span class="p">[</span><span class="s1">&#39;status&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_layer_capacity">
<span class="sig-name descname"><span class="pre">analyze_layer_capacity</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze_layer_capacity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_layer_capacity" title="Link to this definition">¶</a></dt>
<dd><p>Analyze information bottlenecks and layer capacity issues.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_architecture_sanity">
<span class="sig-name descname"><span class="pre">analyze_architecture_sanity</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze_architecture_sanity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_architecture_sanity" title="Link to this definition">¶</a></dt>
<dd><p>Perform comprehensive architecture validation.</p>
<p>Validates network architecture against established deep learning principles
and best practices. Checks for common architectural pitfalls such as
incompatible activation functions, inappropriate depth, and problematic
layer configurations based on research findings.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Analysis results containing:</dt><dd><ul class="simple">
<li><p>issues: List of critical architectural problems</p></li>
<li><p>warnings: List of potential concerns</p></li>
<li><p>status: Overall architecture quality (“PASS”, “WARN”, “FAIL”)</p></li>
<li><p>note: Summary diagnostic message</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Based on research from Bengio et al. (2009) on vanishing gradients,
modern best practices for deep architectures, and activation function
compatibility studies.</p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze_architecture_sanity</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;issues&#39;</span><span class="p">]:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Critical issues found:&quot;</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;issues&#39;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_capacity_data_ratio">
<span class="sig-name descname"><span class="pre">analyze_capacity_data_ratio</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze_capacity_data_ratio"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_capacity_data_ratio" title="Link to this definition">¶</a></dt>
<dd><p>Analyze parameter count relative to training data size.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_convergence_feasibility">
<span class="sig-name descname"><span class="pre">analyze_convergence_feasibility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze_convergence_feasibility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_convergence_feasibility" title="Link to this definition">¶</a></dt>
<dd><p>Assess whether the current setup can theoretically converge.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze">
<span class="sig-name descname"><span class="pre">analyze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/pretraining.html#PreTrainingAnalyzer.analyze"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze" title="Link to this definition">¶</a></dt>
<dd><p>Comprehensive pre-training analysis with clean tabular output.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-neuroscope.diagnostics.training_monitors">
<span id="training-monitoring"></span><h3>Training Monitoring<a class="headerlink" href="#module-neuroscope.diagnostics.training_monitors" title="Link to this heading">¶</a></h3>
<p>Training Monitors for NeuroScope MLP Framework
Real-time monitoring tools for neural network training based on modern deep learning research.
Implements comprehensive training diagnostics with emoji-based status indicators.</p>
<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.diagnostics.training_monitors.</span></span><span class="sig-name descname"><span class="pre">TrainingMonitor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">history_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Comprehensive real-time training monitoring system for neural networks.</p>
<p>Monitors 10 key training health indicators:
- Dead ReLU neurons detection
- Vanishing Gradient Problem (VGP) detection
- Exploding Gradient Problem (EGP) detection
- Weight health analysis
- Learning progress
- Overfitting detection
- Gradient signal-to-noise ratio
- Activation saturation detection (tanh/sigmoid)
- Training plateau detection
- Weight update vs magnitude ratios</p>
<p>Initialize comprehensive training monitor.</p>
<p>Sets up monitoring infrastructure for tracking 10 key training health
indicators during neural network training. Uses research-validated
thresholds and emoji-based status visualization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Optional MLP model instance (can be set later).</p></li>
<li><p><strong>history_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Number of epochs to keep in rolling
history for trend analysis. Defaults to 50.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">monitor</span> <span class="o">=</span> <span class="n">TrainingMonitor</span><span class="p">(</span><span class="n">history_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="n">monitor</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">history_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize comprehensive training monitor.</p>
<p>Sets up monitoring infrastructure for tracking 10 key training health
indicators during neural network training. Uses research-validated
thresholds and emoji-based status visualization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Optional MLP model instance (can be set later).</p></li>
<li><p><strong>history_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Number of epochs to keep in rolling
history for trend analysis. Defaults to 50.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">monitor</span> <span class="o">=</span> <span class="n">TrainingMonitor</span><span class="p">(</span><span class="n">history_size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="n">monitor</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.reset_history">
<span class="sig-name descname"><span class="pre">reset_history</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.reset_history"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.reset_history" title="Link to this definition">¶</a></dt>
<dd><p>Reset all monitoring history.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_relu_dead_neurons">
<span class="sig-name descname"><span class="pre">monitor_relu_dead_neurons</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">activations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_functions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_relu_dead_neurons"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_relu_dead_neurons" title="Link to this definition">¶</a></dt>
<dd><p>Monitor for dead ReLU neurons during training.</p>
<p>Detects neurons that have become inactive (always output zero) which
indicates the “dying ReLU” problem. Uses activation-function-aware
thresholds based on research by Glorot et al. (2011) and He et al. (2015).</p>
<p>Natural sparsity in ReLU networks is expected (~50%), but excessive
sparsity (&gt;90%) indicates dead neurons that cannot learn.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>activations</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[NDArray[np.float64]]</span></code>) – Layer activation outputs.</p></li>
<li><p><strong>activation_functions</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[str]</span></code>, <em>optional</em>) – Activation function names per layer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>(dead_percentage, status_emoji) where status is:</dt><dd><ul class="simple">
<li><p>🟢: Healthy sparsity (&lt;10% dead)</p></li>
<li><p>🟡: Moderate concern (10-30% dead)</p></li>
<li><p>🔴: Critical issue (&gt;30% dead)</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Based on “Deep Sparse Rectifier Neural Networks” (Glorot et al. 2011)
and “Delving Deep into Rectifiers” (He et al. 2015).</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_vanishing_gradients">
<span class="sig-name descname"><span class="pre">monitor_vanishing_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradients</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_vanishing_gradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_vanishing_gradients" title="Link to this definition">¶</a></dt>
<dd><p>Detect vanishing gradient problem using research-validated metrics.</p>
<p>Monitors gradient flow through the network to detect vanishing gradients
based on variance analysis from Glorot &amp; Bengio (2010). Healthy networks
maintain similar gradient variance across layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>gradients</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[NDArray[np.float64]]</span></code>) – Gradient arrays for each layer.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>(vgp_severity, status_emoji) where:</dt><dd><ul class="simple">
<li><p>vgp_severity: Float in [0,1] indicating severity</p></li>
<li><p>status: 🟢 (healthy), 🟡 (warning), 🔴 (critical)</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Implementation based on “Understanding the difficulty of training
deep feedforward neural networks” (Glorot &amp; Bengio 2010).</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_exploding_gradients">
<span class="sig-name descname"><span class="pre">monitor_exploding_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradients</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_exploding_gradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_exploding_gradients" title="Link to this definition">¶</a></dt>
<dd><p>Detect exploding gradient problem using gradient norm analysis.</p>
<p>Monitors gradient magnitudes to detect exploding gradients based on
research by Pascanu et al. (2013). Uses both global norm and per-layer
analysis to identify unstable training dynamics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>gradients</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">list[NDArray[np.float64]]</span></code>) – Gradient arrays for each layer.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>(egp_severity, status_emoji) where:</dt><dd><ul class="simple">
<li><p>egp_severity: Float in [0,1] indicating severity</p></li>
<li><p>status: 🟢 (stable), 🟡 (elevated), 🔴 (exploding)</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)">float</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Based on “On the difficulty of training recurrent neural networks”
(Pascanu et al. 2013) gradient clipping and norm analysis.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_weight_health">
<span class="sig-name descname"><span class="pre">monitor_weight_health</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_weight_health"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_weight_health" title="Link to this definition">¶</a></dt>
<dd><p>Simple, research-backed weight health monitor.
Based on Glorot &amp; Bengio (2010) and He et al. (2015) initialization theory.
:param weights: List of weight matrices</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (health_score, status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_learning_progress">
<span class="sig-name descname"><span class="pre">monitor_learning_progress</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">current_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_learning_progress"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_learning_progress" title="Link to this definition">¶</a></dt>
<dd><p>Research-accurate learning progress monitor.
Based on optimization literature: Bottou (2010), Goodfellow et al. (2016), Smith (2017).
Key insights:
- Progress = consistent loss reduction + convergence stability + generalization health
- Uses exponential moving averages and plateau detection from literature
:param current_loss: Current training loss
:param val_loss: Optional validation loss</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (progress_score, emoji_status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_overfitting">
<span class="sig-name descname"><span class="pre">monitor_overfitting</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_overfitting"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_overfitting" title="Link to this definition">¶</a></dt>
<dd><p>Research-accurate overfitting detection.
Based on Prechelt (1998), Goodfellow et al. (2016), and Caruana et al. (2001).
Key insights:
- Overfitting = increasing generalization gap + validation curve deterioration
:param train_loss: Training loss
:param val_loss: Validation loss</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (overfitting_score, emoji_status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_gradient_snr">
<span class="sig-name descname"><span class="pre">monitor_gradient_snr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradients</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_gradient_snr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_gradient_snr" title="Link to this definition">¶</a></dt>
<dd><p>Calculate Gradient Signal-to-Noise Ratio (GSNR) for optimization health.
- Signal: RMS gradient magnitude (update strength)
- Noise: Coefficient of variation (relative inconsistency)
- GSNR = RMS_magnitude / (std_magnitude + ε)
This measures gradient update consistency.
:param gradients: List of gradient arrays from each layer</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (gsnr_score, emoji_status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_activation_saturation">
<span class="sig-name descname"><span class="pre">monitor_activation_saturation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">activations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_functions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_activation_saturation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_activation_saturation" title="Link to this definition">¶</a></dt>
<dd><p>Research-accurate activation saturation detection.
Based on Glorot &amp; Bengio (2010), Hochreiter (1991), and He et al. (2015).
Key insights:
- Saturation = extreme activation values + poor gradient flow + skewed distributions
- Uses function-specific thresholds and statistical distribution analysis
- Tracks saturation propagation through network layers
:param activations: List of activation arrays from each layer
:param activation_functions: List of activation function names for each layer</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (saturation_score, emoji_status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_plateau">
<span class="sig-name descname"><span class="pre">monitor_plateau</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">current_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_gradients</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_plateau"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_plateau" title="Link to this definition">¶</a></dt>
<dd><p>Research-accurate training plateau detection.
Based on Prechelt (1998), Bengio (2012), and Smith (2017).
Key insights:
- Plateau = statistical stagnation + loss of learning momentum + gradient analysis
- Uses multi-scale analysis and statistical significance testing
- Integrates validation correlation and gradient magnitude trends
:param current_loss: Current training loss
:param val_loss: Optional validation loss for correlation analysis
:param current_gradients: Optional gradient arrays for gradient-based detection</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (plateau_score, emoji_status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_weight_update_ratio">
<span class="sig-name descname"><span class="pre">monitor_weight_update_ratio</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_updates</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><span class="pre">Tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_weight_update_ratio"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_weight_update_ratio" title="Link to this definition">¶</a></dt>
<dd><p>Monitor Weight Update to Weight magnitude Ratios (WUR) for learning rate validation.
Research-based implementation using:
- Smith (2015): Learning rate should produce WUR ~10^-3 to 10^-2 for stable training
- Zeiler (2012): Update magnitude should be proportional to weight magnitude
Formula: WUR = ||weight_update|| / ||weight|| per layer
:param weights: Current weight matrices
:param weight_updates: Weight update matrices (gradients * learning_rate)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of (median_wur, status)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_step">
<span class="sig-name descname"><span class="pre">monitor_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradients</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_updates</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_functions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.monitor_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_step" title="Link to this definition">¶</a></dt>
<dd><p>Perform one monitoring step and return all metrics.
:param epoch: Current epoch number
:param train_loss: Training loss
:param val_loss: Validation loss (optional)
:param activations: Layer activations (optional)
:param gradients: Layer gradients (optional)
:param weights: Layer weights (optional)
:param weight_updates: Weight updates (optional)
:param activation_functions: List of activation function names (optional)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dictionary containing all monitoring results</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.training_monitors.TrainingMonitor.format_monitoring_output">
<span class="sig-name descname"><span class="pre">format_monitoring_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">results</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/training_monitors.html#TrainingMonitor.format_monitoring_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.format_monitoring_output" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-neuroscope.diagnostics.posttraining">
<span id="post-training-evaluation"></span><h3>Post-Training Evaluation<a class="headerlink" href="#module-neuroscope.diagnostics.posttraining" title="Link to this heading">¶</a></h3>
<p>Post-Training Evaluation for NeuroScope MLP Framework
Focused post-training evaluation tools for neural network assessment after training.</p>
<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.diagnostics.posttraining.PostTrainingEvaluator">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.diagnostics.posttraining.</span></span><span class="sig-name descname"><span class="pre">PostTrainingEvaluator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/posttraining.html#PostTrainingEvaluator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Comprehensive post-training evaluation system for neural networks.</p>
<p>Provides thorough analysis of trained model performance including robustness
testing, performance metrics evaluation, and diagnostic assessments. Designed
to validate model quality and identify potential deployment issues after
training completion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – Trained and compiled MLP model instance with initialized weights.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.diagnostics.posttraining.PostTrainingEvaluator.model">
<span class="sig-name descname"><span class="pre">model</span></span><a class="headerlink" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.model" title="Link to this definition">¶</a></dt>
<dd><p>Reference to the trained neural network model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.diagnostics.posttraining.PostTrainingEvaluator.results">
<span class="sig-name descname"><span class="pre">results</span></span><a class="headerlink" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.results" title="Link to this definition">¶</a></dt>
<dd><p>Cached evaluation results from various assessments.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a></p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">neuroscope.diagnostics</span><span class="w"> </span><span class="kn">import</span> <span class="n">PostTrainingEvaluator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span> <span class="o">=</span> <span class="n">PostTrainingEvaluator</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Access detailed results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">robustness</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate_robustness</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">performance</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate_performance</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize evaluator with a trained model.</p>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.posttraining.PostTrainingEvaluator.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/posttraining.html#PostTrainingEvaluator.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize evaluator with a trained model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.posttraining.PostTrainingEvaluator.evaluate_robustness">
<span class="sig-name descname"><span class="pre">evaluate_robustness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_levels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/posttraining.html#PostTrainingEvaluator.evaluate_robustness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.evaluate_robustness" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate model robustness against Gaussian noise.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.posttraining.PostTrainingEvaluator.evaluate_performance">
<span class="sig-name descname"><span class="pre">evaluate_performance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/posttraining.html#PostTrainingEvaluator.evaluate_performance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.evaluate_performance" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate model performance metrics.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.posttraining.PostTrainingEvaluator.evaluate_stability">
<span class="sig-name descname"><span class="pre">evaluate_stability</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><span class="pre">Dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><span class="pre">Any</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/neuroscope/diagnostics/posttraining.html#PostTrainingEvaluator.evaluate_stability"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.evaluate_stability" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate prediction stability across similar inputs. (K Neighbor Approach)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.diagnostics.posttraining.PostTrainingEvaluator.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><span class="pre">ndarray</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/diagnostics/posttraining.html#PostTrainingEvaluator.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.evaluate" title="Link to this definition">¶</a></dt>
<dd><p>Run comprehensive model evaluation and generate summary report.</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="visualization-module">
<h2>Visualization Module<a class="headerlink" href="#visualization-module" title="Link to this heading">¶</a></h2>
<section id="module-neuroscope.viz.plots">
<span id="plotting-tools"></span><h3>Plotting Tools<a class="headerlink" href="#module-neuroscope.viz.plots" title="Link to this heading">¶</a></h3>
<p>NeuroScope Visualization Module
High-quality plotting tools for neural network training analysis.</p>
<dl class="py class">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neuroscope.viz.plots.</span></span><span class="sig-name descname"><span class="pre">Visualizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hist</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.viz.plots.Visualizer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>High quality visualization tool for neural network training analysis.</p>
<p>Provides comprehensive plotting capabilities for analyzing training dynamics,
network behavior, and diagnostic information. Creates professional-grade
figures suitable for research publications and presentations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hist</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>) – Complete training history from model.fit() containing:
- history: Training/validation metrics per epoch
- weights/biases: Final network parameters
- activations/gradients: Sample network internals
- <a href="#id1"><span class="problematic" id="id2">*</span></a>_stats_over_epochs: Statistical evolution during training</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.hist">
<span class="sig-name descname"><span class="pre">hist</span></span><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.hist" title="Link to this definition">¶</a></dt>
<dd><p>Complete training history data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.history">
<span class="sig-name descname"><span class="pre">history</span></span><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.history" title="Link to this definition">¶</a></dt>
<dd><p>Training metrics (loss, accuracy) evolution.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">weights/biases</span></span></dt>
<dd><p>Final network parameters.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">activations/gradients</span></span></dt>
<dd><p>Representative network internals.</p>
</dd></dl>

<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">neuroscope.viz</span><span class="w"> </span><span class="kn">import</span> <span class="n">Visualizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span> <span class="o">=</span> <span class="n">Visualizer</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_learning_curves</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_activation_distribution</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_gradient_flow</span><span class="p">()</span>
</pre></div>
</div>
<p>Initialize visualizer with comprehensive training history.</p>
<p>Sets up visualization infrastructure and applies publication-quality
styling to all plots. Automatically extracts relevant data components
for different types of analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hist</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>) – Training history from model.fit() containing all
training statistics, network states, and diagnostic information.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hist</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize visualizer with comprehensive training history.</p>
<p>Sets up visualization infrastructure and applies publication-quality
styling to all plots. Automatically extracts relevant data components
for different types of analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hist</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>) – Training history from model.fit() containing all
training statistics, network states, and diagnostic information.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.plot_learning_curves">
<span class="sig-name descname"><span class="pre">plot_learning_curves</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(9,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ci</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">markers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'accuracy'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_learning_curves"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.plot_learning_curves" title="Link to this definition">¶</a></dt>
<dd><p>Plot training and validation learning curves.</p>
<p>Creates publication-quality subplot showing loss and metric evolution
during training. Automatically detects available data and applies
consistent styling with optional confidence intervals.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>figsize</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple[int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int]</span></code>, <em>optional</em>) – Figure dimensions (width, height). Defaults to (9, 4).</p></li>
<li><p><strong>ci</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to add confidence intervals using moving window statistics.
Defaults to False.</p></li>
<li><p><strong>markers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to show markers on line plots. Defaults to True.</p></li>
<li><p><strong>save_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Path to save the figure. Defaults to None.</p></li>
<li><p><strong>metric</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Name of the metric for y-axis label. Defaults to ‘accuracy’.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_learning_curves</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">ci</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;curves.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.plot_activation_hist">
<span class="sig-name descname"><span class="pre">plot_activation_hist</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(9,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kde</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_activation_hist"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.plot_activation_hist" title="Link to this definition">¶</a></dt>
<dd><p>Plot activation value distributions across network layers.</p>
<p>Visualizes the distribution of activation values for each layer at a specific
epoch, aggregated from all mini-batches. Useful for detecting activation
saturation, dead neurons, and distribution shifts during training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Specific epoch to plot. If None, uses last epoch. Defaults to None.</p></li>
<li><p><strong>figsize</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple[int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int]</span></code>, <em>optional</em>) – Figure dimensions. Defaults to (9, 4).</p></li>
<li><p><strong>kde</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to use KDE-style smoothing for smoother curves. Defaults to False.</p></li>
<li><p><strong>last_layer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to include output layer. Defaults to False.</p></li>
<li><p><strong>save_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Path to save the figure. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_activation_hist</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;activations.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.plot_gradient_hist">
<span class="sig-name descname"><span class="pre">plot_gradient_hist</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(9,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kde</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_gradient_hist"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.plot_gradient_hist" title="Link to this definition">¶</a></dt>
<dd><p>Plot gradient value distributions across network layers.</p>
<p>Visualizes gradient distributions to detect vanishing/exploding gradient
problems, gradient flow issues, and training stability. Shows zero-line
reference for assessing gradient symmetry and magnitude.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <em>optional</em>) – Specific epoch to plot. If None, uses last epoch. Defaults to None.</p></li>
<li><p><strong>figsize</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">tuple[int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int]</span></code>, <em>optional</em>) – Figure dimensions. Defaults to (9, 4).</p></li>
<li><p><strong>kde</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to use KDE-style smoothing. Defaults to False.</p></li>
<li><p><strong>last_layer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></a>, <em>optional</em>) – Whether to include output layer gradients. Defaults to False.</p></li>
<li><p><strong>save_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <em>optional</em>) – Path to save the figure. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Gradient distributions should be roughly symmetric around zero for healthy training.
Very narrow distributions may indicate vanishing gradients, while very wide
distributions may indicate exploding gradients.</p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">viz</span><span class="o">.</span><span class="n">plot_gradient_hist</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;gradients.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.plot_weight_hist">
<span class="sig-name descname"><span class="pre">plot_weight_hist</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(9,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kde</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_weight_hist"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.plot_weight_hist" title="Link to this definition">¶</a></dt>
<dd><p>Uses aggregated samples from all mini-batches within
an epoch to create representative distributions. Shows weight evolution patterns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> – Specific epoch to plot (default: last epoch)</p></li>
<li><p><strong>figsize</strong> – Figure size tuple</p></li>
<li><p><strong>kde</strong> – Whether to use KDE-style smoothing</p></li>
<li><p><strong>last_layer</strong> – Whether to include output layer (default: False, hidden layers only)</p></li>
<li><p><strong>save_path</strong> – Path to save figure</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.plot_activation_stats">
<span class="sig-name descname"><span class="pre">plot_activation_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">activation_stats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(12,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_activation_stats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.plot_activation_stats" title="Link to this definition">¶</a></dt>
<dd><p>Plot activation statistics over time with both mean and std.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>activation_stats</strong> – Dict of layer activation stats OR None to use class data
Format: {‘layer_0’: {‘mean’: […], ‘std’: […]}, …}</p></li>
<li><p><strong>figsize</strong> – Figure size tuple</p></li>
<li><p><strong>save_path</strong> – Path to save figure</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.plot_gradient_stats">
<span class="sig-name descname"><span class="pre">plot_gradient_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(12,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_gradient_stats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.plot_gradient_stats" title="Link to this definition">¶</a></dt>
<dd><p>Plot gradient statistics over time with both mean and std.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.plot_weight_stats">
<span class="sig-name descname"><span class="pre">plot_weight_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(12,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_weight_stats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.plot_weight_stats" title="Link to this definition">¶</a></dt>
<dd><p>Plot weight statistics over time with both mean and std.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.plot_update_ratios">
<span class="sig-name descname"><span class="pre">plot_update_ratios</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">update_ratios</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(12,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_update_ratios"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.plot_update_ratios" title="Link to this definition">¶</a></dt>
<dd><p>Plot weight update ratios per layer across epochs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>update_ratios</strong> – Dict of layer update ratios (optional - uses collected data if None)
Format: {‘layer_0’: [ratio_epoch_0, ratio_epoch_1, …], …}</p></li>
<li><p><strong>figsize</strong> – Figure size tuple</p></li>
<li><p><strong>save_path</strong> – Path to save figure</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.plot_gradient_norms">
<span class="sig-name descname"><span class="pre">plot_gradient_norms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradient_norms</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">figsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(12,</span> <span class="pre">4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reference_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_gradient_norms"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.plot_gradient_norms" title="Link to this definition">¶</a></dt>
<dd><p>Plot gradient norms per layer over epochs.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neuroscope.viz.plots.Visualizer.plot_training_animation">
<span class="sig-name descname"><span class="pre">plot_training_animation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'dark'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/neuroscope/viz/plots.html#Visualizer.plot_training_animation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neuroscope.viz.plots.Visualizer.plot_training_animation" title="Link to this definition">¶</a></dt>
<dd><p>Creates a comprehensive 4-panel GIF animation showing:
1. Loss curves over time
2. Accuracy curves over time
3. Current metrics bar chart
4. Gradient flow analysis
Speed automatically adjusts based on epoch count for smooth motion feel.
:param bg: Theme (‘dark’ or ‘light’)
:param save_path: Path to save GIF (defaults to ‘mlp_training_animation.gif’)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Path to saved GIF file</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="visualization_gallery.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Visualization Gallery</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="technical_deep_dive.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Technical Deep Dive: Neural Network Diagnostics</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, Ahmad Raza
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">API Reference</a><ul>
<li><a class="reference internal" href="#core-module">Core Module</a><ul>
<li><a class="reference internal" href="#module-neuroscope">neuroscope</a><ul>
<li><a class="reference internal" href="#neuroscope.MLP"><code class="docutils literal notranslate"><span class="pre">MLP</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.MLP.weights"><code class="docutils literal notranslate"><span class="pre">MLP.weights</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.MLP.biases"><code class="docutils literal notranslate"><span class="pre">MLP.biases</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.MLP.compiled"><code class="docutils literal notranslate"><span class="pre">MLP.compiled</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.MLP.__init__"><code class="docutils literal notranslate"><span class="pre">MLP.__init__()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.MLP.compile"><code class="docutils literal notranslate"><span class="pre">MLP.compile()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.MLP.evaluate"><code class="docutils literal notranslate"><span class="pre">MLP.evaluate()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.MLP.fit"><code class="docutils literal notranslate"><span class="pre">MLP.fit()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.MLP.fit_batch"><code class="docutils literal notranslate"><span class="pre">MLP.fit_batch()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.MLP.fit_fast"><code class="docutils literal notranslate"><span class="pre">MLP.fit_fast()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.MLP.predict"><code class="docutils literal notranslate"><span class="pre">MLP.predict()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.MLP.reset_all"><code class="docutils literal notranslate"><span class="pre">MLP.reset_all()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.MLP.reset_optimizer"><code class="docutils literal notranslate"><span class="pre">MLP.reset_optimizer()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.MLP.reset_weights"><code class="docutils literal notranslate"><span class="pre">MLP.reset_weights()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neuroscope.PreTrainingAnalyzer"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.PreTrainingAnalyzer.model"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.model</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PreTrainingAnalyzer.results"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.results</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PreTrainingAnalyzer.__init__"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.__init__()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PreTrainingAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PreTrainingAnalyzer.analyze_architecture_sanity"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze_architecture_sanity()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PreTrainingAnalyzer.analyze_capacity_data_ratio"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze_capacity_data_ratio()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PreTrainingAnalyzer.analyze_convergence_feasibility"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze_convergence_feasibility()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PreTrainingAnalyzer.analyze_initial_loss"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze_initial_loss()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PreTrainingAnalyzer.analyze_layer_capacity"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze_layer_capacity()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PreTrainingAnalyzer.analyze_weight_init"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze_weight_init()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.__init__"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.format_monitoring_output"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.format_monitoring_output()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.monitor_activation_saturation"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_activation_saturation()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.monitor_exploding_gradients"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_exploding_gradients()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.monitor_gradient_snr"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_gradient_snr()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.monitor_learning_progress"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_learning_progress()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.monitor_overfitting"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_overfitting()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.monitor_plateau"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_plateau()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.monitor_relu_dead_neurons"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_relu_dead_neurons()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.monitor_step"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_step()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.monitor_vanishing_gradients"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_vanishing_gradients()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.monitor_weight_health"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_weight_health()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.monitor_weight_update_ratio"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_weight_update_ratio()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TrainingMonitor.reset_history"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.reset_history()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neuroscope.PostTrainingEvaluator"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.PostTrainingEvaluator.model"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.model</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PostTrainingEvaluator.results"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.results</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PostTrainingEvaluator.__init__"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.__init__()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PostTrainingEvaluator.evaluate"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.evaluate()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PostTrainingEvaluator.evaluate_performance"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.evaluate_performance()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PostTrainingEvaluator.evaluate_robustness"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.evaluate_robustness()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PostTrainingEvaluator.evaluate_stability"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.evaluate_stability()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neuroscope.Visualizer"><code class="docutils literal notranslate"><span class="pre">Visualizer</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.Visualizer.hist"><code class="docutils literal notranslate"><span class="pre">Visualizer.hist</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.Visualizer.history"><code class="docutils literal notranslate"><span class="pre">Visualizer.history</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.Visualizer.__init__"><code class="docutils literal notranslate"><span class="pre">Visualizer.__init__()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.Visualizer.plot_activation_hist"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_activation_hist()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.Visualizer.plot_activation_stats"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_activation_stats()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.Visualizer.plot_gradient_hist"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_gradient_hist()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.Visualizer.plot_gradient_norms"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_gradient_norms()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.Visualizer.plot_gradient_stats"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_gradient_stats()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.Visualizer.plot_learning_curves"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_learning_curves()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.Visualizer.plot_training_animation"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_training_animation()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.Visualizer.plot_update_ratios"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_update_ratios()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.Visualizer.plot_weight_hist"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_weight_hist()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.Visualizer.plot_weight_stats"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_weight_stats()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neuroscope.PTA"><code class="docutils literal notranslate"><span class="pre">PTA</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.TM"><code class="docutils literal notranslate"><span class="pre">TM</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.PTE"><code class="docutils literal notranslate"><span class="pre">PTE</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.VIZ"><code class="docutils literal notranslate"><span class="pre">VIZ</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mse"><code class="docutils literal notranslate"><span class="pre">mse()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.bce"><code class="docutils literal notranslate"><span class="pre">bce()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.cce"><code class="docutils literal notranslate"><span class="pre">cce()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mse_with_reg"><code class="docutils literal notranslate"><span class="pre">mse_with_reg()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.bce_with_reg"><code class="docutils literal notranslate"><span class="pre">bce_with_reg()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.cce_with_reg"><code class="docutils literal notranslate"><span class="pre">cce_with_reg()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.accuracy_binary"><code class="docutils literal notranslate"><span class="pre">accuracy_binary()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.accuracy_multiclass"><code class="docutils literal notranslate"><span class="pre">accuracy_multiclass()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.rmse"><code class="docutils literal notranslate"><span class="pre">rmse()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mae"><code class="docutils literal notranslate"><span class="pre">mae()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.r2_score"><code class="docutils literal notranslate"><span class="pre">r2_score()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.f1_score"><code class="docutils literal notranslate"><span class="pre">f1_score()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.precision"><code class="docutils literal notranslate"><span class="pre">precision()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.recall"><code class="docutils literal notranslate"><span class="pre">recall()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.relu"><code class="docutils literal notranslate"><span class="pre">relu()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.leaky_relu"><code class="docutils literal notranslate"><span class="pre">leaky_relu()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.sigmoid"><code class="docutils literal notranslate"><span class="pre">sigmoid()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.tanh"><code class="docutils literal notranslate"><span class="pre">tanh()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.selu"><code class="docutils literal notranslate"><span class="pre">selu()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.softmax"><code class="docutils literal notranslate"><span class="pre">softmax()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.he_init"><code class="docutils literal notranslate"><span class="pre">he_init()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.xavier_init"><code class="docutils literal notranslate"><span class="pre">xavier_init()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.random_init"><code class="docutils literal notranslate"><span class="pre">random_init()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.selu_init"><code class="docutils literal notranslate"><span class="pre">selu_init()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#mlp-module">MLP Module</a><ul>
<li><a class="reference internal" href="#module-neuroscope.mlp.mlp">Multi-Layer Perceptron</a><ul>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP"><code class="docutils literal notranslate"><span class="pre">MLP</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.weights"><code class="docutils literal notranslate"><span class="pre">MLP.weights</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.biases"><code class="docutils literal notranslate"><span class="pre">MLP.biases</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.compiled"><code class="docutils literal notranslate"><span class="pre">MLP.compiled</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.__init__"><code class="docutils literal notranslate"><span class="pre">MLP.__init__()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.reset_weights"><code class="docutils literal notranslate"><span class="pre">MLP.reset_weights()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.reset_optimizer"><code class="docutils literal notranslate"><span class="pre">MLP.reset_optimizer()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.reset_all"><code class="docutils literal notranslate"><span class="pre">MLP.reset_all()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.compile"><code class="docutils literal notranslate"><span class="pre">MLP.compile()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.predict"><code class="docutils literal notranslate"><span class="pre">MLP.predict()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.evaluate"><code class="docutils literal notranslate"><span class="pre">MLP.evaluate()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.fit"><code class="docutils literal notranslate"><span class="pre">MLP.fit()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.fit_fast"><code class="docutils literal notranslate"><span class="pre">MLP.fit_fast()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.mlp.MLP.fit_batch"><code class="docutils literal notranslate"><span class="pre">MLP.fit_batch()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-neuroscope.mlp.activations">Activation Functions</a><ul>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.sigmoid"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.sigmoid()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.sigmoid_derivative"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.sigmoid_derivative()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.softmax"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.softmax()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.tanh"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.tanh()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.tanh_derivative"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.tanh_derivative()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.relu"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.relu()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.relu_derivative"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.relu_derivative()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.leaky_relu"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.leaky_relu()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.leaky_relu_derivative"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.leaky_relu_derivative()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.selu"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.selu()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.selu_derivative"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.selu_derivative()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.inverted_dropout"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.inverted_dropout()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.activations.ActivationFunctions.alpha_dropout"><code class="docutils literal notranslate"><span class="pre">ActivationFunctions.alpha_dropout()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-neuroscope.mlp.losses">Loss Functions</a><ul>
<li><a class="reference internal" href="#neuroscope.mlp.losses.LossFunctions"><code class="docutils literal notranslate"><span class="pre">LossFunctions</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.mlp.losses.LossFunctions.mse"><code class="docutils literal notranslate"><span class="pre">LossFunctions.mse()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.losses.LossFunctions.bce"><code class="docutils literal notranslate"><span class="pre">LossFunctions.bce()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.losses.LossFunctions.bce_with_reg"><code class="docutils literal notranslate"><span class="pre">LossFunctions.bce_with_reg()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.losses.LossFunctions.cce"><code class="docutils literal notranslate"><span class="pre">LossFunctions.cce()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.losses.LossFunctions.cce_with_reg"><code class="docutils literal notranslate"><span class="pre">LossFunctions.cce_with_reg()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.losses.LossFunctions.mse_with_reg"><code class="docutils literal notranslate"><span class="pre">LossFunctions.mse_with_reg()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-neuroscope.mlp.metrics">Metrics</a><ul>
<li><a class="reference internal" href="#neuroscope.mlp.metrics.Metrics"><code class="docutils literal notranslate"><span class="pre">Metrics</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.mlp.metrics.Metrics.accuracy_multiclass"><code class="docutils literal notranslate"><span class="pre">Metrics.accuracy_multiclass()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.metrics.Metrics.accuracy_binary"><code class="docutils literal notranslate"><span class="pre">Metrics.accuracy_binary()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.metrics.Metrics.mse"><code class="docutils literal notranslate"><span class="pre">Metrics.mse()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.metrics.Metrics.rmse"><code class="docutils literal notranslate"><span class="pre">Metrics.rmse()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.metrics.Metrics.mae"><code class="docutils literal notranslate"><span class="pre">Metrics.mae()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.metrics.Metrics.r2_score"><code class="docutils literal notranslate"><span class="pre">Metrics.r2_score()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.metrics.Metrics.precision"><code class="docutils literal notranslate"><span class="pre">Metrics.precision()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.metrics.Metrics.recall"><code class="docutils literal notranslate"><span class="pre">Metrics.recall()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.metrics.Metrics.f1_score"><code class="docutils literal notranslate"><span class="pre">Metrics.f1_score()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-neuroscope.mlp.initializers">Weight Initializers</a><ul>
<li><a class="reference internal" href="#neuroscope.mlp.initializers.WeightInits"><code class="docutils literal notranslate"><span class="pre">WeightInits</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.mlp.initializers.WeightInits.he_init"><code class="docutils literal notranslate"><span class="pre">WeightInits.he_init()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.initializers.WeightInits.xavier_init"><code class="docutils literal notranslate"><span class="pre">WeightInits.xavier_init()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.initializers.WeightInits.random_init"><code class="docutils literal notranslate"><span class="pre">WeightInits.random_init()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.initializers.WeightInits.selu_init"><code class="docutils literal notranslate"><span class="pre">WeightInits.selu_init()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.initializers.WeightInits.smart_init"><code class="docutils literal notranslate"><span class="pre">WeightInits.smart_init()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-neuroscope.mlp.utils">Utilities</a><ul>
<li><a class="reference internal" href="#neuroscope.mlp.utils.Utils"><code class="docutils literal notranslate"><span class="pre">Utils</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.mlp.utils.Utils.get_batches"><code class="docutils literal notranslate"><span class="pre">Utils.get_batches()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.utils.Utils.get_batches_fast"><code class="docutils literal notranslate"><span class="pre">Utils.get_batches_fast()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.utils.Utils.gradient_clipping"><code class="docutils literal notranslate"><span class="pre">Utils.gradient_clipping()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.utils.Utils.validate_array_input"><code class="docutils literal notranslate"><span class="pre">Utils.validate_array_input()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.utils.Utils.validate_layer_dims"><code class="docutils literal notranslate"><span class="pre">Utils.validate_layer_dims()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.mlp.utils.Utils.check_numerical_stability"><code class="docutils literal notranslate"><span class="pre">Utils.check_numerical_stability()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#diagnostics-module">Diagnostics Module</a><ul>
<li><a class="reference internal" href="#module-neuroscope.diagnostics.pretraining">Pre-Training Analysis</a><ul>
<li><a class="reference internal" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.model"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.model</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.results"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.results</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.__init__"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.__init__()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_initial_loss"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze_initial_loss()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_weight_init"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze_weight_init()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_layer_capacity"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze_layer_capacity()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_architecture_sanity"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze_architecture_sanity()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_capacity_data_ratio"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze_capacity_data_ratio()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze_convergence_feasibility"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze_convergence_feasibility()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.pretraining.PreTrainingAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">PreTrainingAnalyzer.analyze()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-neuroscope.diagnostics.training_monitors">Training Monitoring</a><ul>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.__init__"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.reset_history"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.reset_history()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_relu_dead_neurons"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_relu_dead_neurons()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_vanishing_gradients"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_vanishing_gradients()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_exploding_gradients"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_exploding_gradients()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_weight_health"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_weight_health()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_learning_progress"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_learning_progress()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_overfitting"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_overfitting()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_gradient_snr"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_gradient_snr()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_activation_saturation"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_activation_saturation()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_plateau"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_plateau()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_weight_update_ratio"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_weight_update_ratio()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.monitor_step"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.monitor_step()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.training_monitors.TrainingMonitor.format_monitoring_output"><code class="docutils literal notranslate"><span class="pre">TrainingMonitor.format_monitoring_output()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-neuroscope.diagnostics.posttraining">Post-Training Evaluation</a><ul>
<li><a class="reference internal" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.model"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.model</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.results"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.results</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.__init__"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.__init__()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.evaluate_robustness"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.evaluate_robustness()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.evaluate_performance"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.evaluate_performance()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.evaluate_stability"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.evaluate_stability()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.diagnostics.posttraining.PostTrainingEvaluator.evaluate"><code class="docutils literal notranslate"><span class="pre">PostTrainingEvaluator.evaluate()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#visualization-module">Visualization Module</a><ul>
<li><a class="reference internal" href="#module-neuroscope.viz.plots">Plotting Tools</a><ul>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer"><code class="docutils literal notranslate"><span class="pre">Visualizer</span></code></a><ul>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.hist"><code class="docutils literal notranslate"><span class="pre">Visualizer.hist</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.history"><code class="docutils literal notranslate"><span class="pre">Visualizer.history</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.__init__"><code class="docutils literal notranslate"><span class="pre">Visualizer.__init__()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.plot_learning_curves"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_learning_curves()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.plot_activation_hist"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_activation_hist()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.plot_gradient_hist"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_gradient_hist()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.plot_weight_hist"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_weight_hist()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.plot_activation_stats"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_activation_stats()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.plot_gradient_stats"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_gradient_stats()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.plot_weight_stats"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_weight_stats()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.plot_update_ratios"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_update_ratios()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.plot_gradient_norms"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_gradient_norms()</span></code></a></li>
<li><a class="reference internal" href="#neuroscope.viz.plots.Visualizer.plot_training_animation"><code class="docutils literal notranslate"><span class="pre">Visualizer.plot_training_animation()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=38b66d78"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    </body>
</html>